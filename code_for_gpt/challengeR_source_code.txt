

# FILE: /mnt/data/challengeR_extracted/challengeR/vignettes/SingleTask_aggregate-then-rank.R
## Single task, aggregate-then-rank ranking

## 1\. Load package

library(challengeR)

## 2\. Load data

if (!requireNamespace("permute", quietly = TRUE)) install.packages("permute")

n=50

set.seed(4)
strip=runif(n,.9,1)
c_ideal=cbind(task="c_ideal",
            rbind(
              data.frame(alg_name="A1",value=runif(n,.9,1),case=1:n),
              data.frame(alg_name="A2",value=runif(n,.8,.89),case=1:n),
              data.frame(alg_name="A3",value=runif(n,.7,.79),case=1:n),
              data.frame(alg_name="A4",value=runif(n,.6,.69),case=1:n),
              data.frame(alg_name="A5",value=runif(n,.5,.59),case=1:n)
            ))

set.seed(1)
c_random=data.frame(task="c_random",
                       alg_name=factor(paste0("A",rep(1:5,each=n))),
                       value=plogis(rnorm(5*n,1.5,1)),case=rep(1:n,times=5)
                       )

strip2=seq(.8,1,length.out=5)
a=permute::allPerms(1:5)
c_worstcase=data.frame(task="c_worstcase",
                     alg_name=c(t(a)),
                     value=rep(strip2,nrow(a)),
                     case=rep(1:nrow(a),each=5)
                     )
c_worstcase=rbind(c_worstcase,
                data.frame(task="c_worstcase",alg_name=1:5,value=strip2,case=max(c_worstcase$case)+1)
          )
c_worstcase$alg_name=factor(c_worstcase$alg_name,labels=paste0("A",1:5))

data_matrix=rbind(c_ideal, c_random, c_worstcase)

## 3 Perform ranking

### 3.1 Define challenge object

dataSubset=subset(data_matrix, task=="c_random")

challenge=as.challenge(dataSubset, algorithm="alg_name", case="case", value="value", smallBetter = FALSE)

### 3.2 Perform ranking

ranking=challenge%>%aggregateThenRank(FUN = mean, na.treat=0, ties.method = "min")  

## 4\. Perform bootstrapping

library(doParallel)
library(doRNG)
registerDoParallel(cores=8)
registerDoRNG(1)
ranking_bootstrapped=ranking%>%bootstrap(nboot=1000, parallel=TRUE, progress="none")
stopImplicitCluster()

## 5\. Generate the report
ranking_bootstrapped %>% 
  report(title="singleTaskChallengeExample", # used for the title of the report
         file = "SingleTask_aggregate-then-rank", 
         format = "PDF", # format can be "PDF", "HTML" or "Word"
         latex_engine="pdflatex", #LaTeX engine for producing PDF output. Options are "pdflatex", "lualatex", and "xelatex"
         clean=TRUE #optional. Using TRUE will clean intermediate files that are created during rendering.
        ) 


# FILE: /mnt/data/challengeR_extracted/challengeR/vignettes/MultiTask_test-then-rank.R
## Multi-task, test-then-rank based on Wilcoxon signed rank ranking

## 1\. Load package

library(challengeR)

## 2\. Load data

if (!requireNamespace("permute", quietly = TRUE)) install.packages("permute")

n=50

set.seed(4)
strip=runif(n,.9,1)
c_ideal=cbind(task="c_ideal",
            rbind(
              data.frame(alg_name="A1",value=runif(n,.9,1),case=1:n),
              data.frame(alg_name="A2",value=runif(n,.8,.89),case=1:n),
              data.frame(alg_name="A3",value=runif(n,.7,.79),case=1:n),
              data.frame(alg_name="A4",value=runif(n,.6,.69),case=1:n),
              data.frame(alg_name="A5",value=runif(n,.5,.59),case=1:n)
            ))

set.seed(1)
c_random=data.frame(task="c_random",
                       alg_name=factor(paste0("A",rep(1:5,each=n))),
                       value=plogis(rnorm(5*n,1.5,1)),case=rep(1:n,times=5)
                       )

strip2=seq(.8,1,length.out=5)
a=permute::allPerms(1:5)
c_worstcase=data.frame(task="c_worstcase",
                     alg_name=c(t(a)),
                     value=rep(strip2,nrow(a)),
                     case=rep(1:nrow(a),each=5)
                     )
c_worstcase=rbind(c_worstcase,
                data.frame(task="c_worstcase",alg_name=1:5,value=strip2,case=max(c_worstcase$case)+1)
          )
c_worstcase$alg_name=factor(c_worstcase$alg_name,labels=paste0("A",1:5))

data_matrix=rbind(c_ideal, c_random, c_worstcase)

## 3 Perform ranking

### 3.1 Define challenge object

challenge=as.challenge(data_matrix, 
					 by="task", 
					 algorithm="alg_name", case="case", value="value", 
					 smallBetter = FALSE)

### 3.2 Perform ranking

#{r, eval=F, echo=T}
ranking=challenge%>%testThenRank(alpha=0.05, 
                                 p.adjust.method="none",  
                                 na.treat=0, 
                                 ties.method = "min"
                     )

## 4\. Perform bootstrapping

library(doParallel)
library(doRNG)
registerDoParallel(cores=8)
registerDoRNG(1)
ranking_bootstrapped=ranking%>%bootstrap(nboot=1000, parallel=TRUE, progress="none")
stopImplicitCluster()

## 5\. Generate the report

meanRanks=ranking%>%consensus(method = "euclidean") 
meanRanks # note that there may be ties (i.e. some algorithms have identical mean rank)

ranking_bootstrapped %>% 
  report(consensus=meanRanks,
         title="multiTaskChallengeExample",
         file = "MultiTask_test-then-rank", 
         format = "PDF", # format can be "PDF", "HTML" or "Word"
         latex_engine="pdflatex",#LaTeX engine for producing PDF output. Options are "pdflatex", "lualatex", and "xelatex"
         clean=TRUE #optional. Using TRUE will clean intermediate files that are created during rendering.
        )


# FILE: /mnt/data/challengeR_extracted/challengeR/vignettes/MultiTask_rank-then-aggregate.R
## Multitask, rank-then-aggregate ranking

## 1\. Load package

library(challengeR)

## 2\. Load data

if (!requireNamespace("permute", quietly = TRUE)) install.packages("permute")

n=50

set.seed(4)
strip=runif(n,.9,1)
c_ideal=cbind(task="c_ideal",
            rbind(
              data.frame(alg_name="A1",value=runif(n,.9,1),case=1:n),
              data.frame(alg_name="A2",value=runif(n,.8,.89),case=1:n),
              data.frame(alg_name="A3",value=runif(n,.7,.79),case=1:n),
              data.frame(alg_name="A4",value=runif(n,.6,.69),case=1:n),
              data.frame(alg_name="A5",value=runif(n,.5,.59),case=1:n)
            ))

set.seed(1)
c_random=data.frame(task="c_random",
                       alg_name=factor(paste0("A",rep(1:5,each=n))),
                       value=plogis(rnorm(5*n,1.5,1)),case=rep(1:n,times=5)
                       )

strip2=seq(.8,1,length.out=5)
a=permute::allPerms(1:5)
c_worstcase=data.frame(task="c_worstcase",
                     alg_name=c(t(a)),
                     value=rep(strip2,nrow(a)),
                     case=rep(1:nrow(a),each=5)
                     )
c_worstcase=rbind(c_worstcase,
                data.frame(task="c_worstcase",alg_name=1:5,value=strip2,case=max(c_worstcase$case)+1)
          )
c_worstcase$alg_name=factor(c_worstcase$alg_name,labels=paste0("A",1:5))

data_matrix=rbind(c_ideal, c_random, c_worstcase)

## 3 Perform ranking

### 3.1 Define challenge object

challenge=as.challenge(data_matrix, 
					 by="task", 
					 algorithm="alg_name", case="case", value="value", 
					 smallBetter = FALSE)

### 3.2 Perform ranking

ranking=challenge%>%rankThenAggregate(FUN = mean,
                                      ties.method = "min"
                                      )

## 4\. Perform bootstrapping

library(doParallel)
library(doRNG)
registerDoParallel(cores=8)
registerDoRNG(1)
ranking_bootstrapped=ranking%>%bootstrap(nboot=1000, parallel=TRUE, progress="none")
stopImplicitCluster()

## 5\. Generate the report

meanRanks=ranking%>%consensus(method = "euclidean") 
meanRanks # note that there may be ties (i.e. some algorithms have identical mean rank)

ranking_bootstrapped %>% 
  report(consensus=meanRanks,
         title="multiTaskChallengeExample",
         file = "MultiTask_rank-then-aggregate", 
         format = "PDF", # format can be "PDF", "HTML" or "Word"
         latex_engine="pdflatex",#LaTeX engine for producing PDF output. Options are "pdflatex", "lualatex", and "xelatex"
         clean=TRUE #optional. Using TRUE will clean intermediate files that are created during rendering.
        )


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

library(testthat)
library(challengeR)
Sys.setenv("LANGUAGE" = "EN")
test_check("challengeR")



# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-significanceMap.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("significance map for single-task data set has no title", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  actualPlot <- significanceMap(ranking)
  expect_is(actualPlot, "ggplot")
  expect_equal(actualPlot$labels$title, NULL)
})

test_that("significance map for multi-task data set have titles", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  actualPlots <- significanceMap(ranking)
  actualPlotTask1 <- actualPlots[[1]]
  actualPlotTask2 <- actualPlots[[2]]

  expect_is(actualPlotTask1, "ggplot")
  expect_equal(actualPlotTask1$labels$title, "T1")

  expect_is(actualPlotTask2, "ggplot")
  expect_equal(actualPlotTask2$labels$title, "T2")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-testThenRank.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("test-then-rank raises warning for one case", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_warning(ranking <- challenge%>%testThenRank(),
                 "Only one case in task.", fixed = TRUE)

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("test-then-rank raises warning for one algorithm", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_warning(ranking <- challenge%>%testThenRank(),
                 "Only one algorithm available in task 'T1'.", fixed = TRUE)
})

test_that("test-then-rank works with two algorithms, small values are better", {
  data <- rbind(
    data.frame(algo="A1", value=0.2, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank()

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 1, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("test-then-rank works with two algorithms, large values are better", {
  data <- rbind(
    data.frame(algo="A1", value=0.2, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%testThenRank()

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 2),
    "A2" = data.frame(prop_significance = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("test-then-rank works for ties method 'max'", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A1", value=0.6, case="C2"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.8, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank(ties.method = "max")

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 2),
    "A2" = data.frame(prop_significance = 0, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("test-then-rank raises error for invalid ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A1", value=0.6, case="C2"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.8, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%testThenRank(ties.method = "maxx"),
               "'arg' should be one of", fixed = TRUE)
})

test_that("test-then-rank raises error for invalid ties method even when no ties present", {
  data <- rbind(
    data.frame(algo="A1", value=0.2, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%testThenRank(ties.method = "maxx"),
               "'arg' should be one of", fixed = TRUE)
})

test_that("test-then-rank raises error when no NA treatment specified but NAs are contained", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%testThenRank(),
               "argument \"na.treat\" is missing, with no default", fixed = TRUE)
})

test_that("test-then-rank raises error when invalid NA treatment specified and NAs are contained", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%testThenRank(na.treat = "na.rmx"),
               "Argument 'na.treat' is invalid. It can be 'na.rm', numeric value or function.", fixed = TRUE)
})

test_that("specified NA treatment does not influence ranking when no NAs are contained", {
  data <- rbind(
    data.frame(algo="A1", value=0.2, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank(na.treat = 0)

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 1, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("NAs are replaced by numeric value", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank(na.treat = 100.0)

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("NAs are replaced by function value", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  replacementFunction <- function(x) { 0.0 }

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank(na.treat = replacementFunction)

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 1, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("NAs are removed", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A1", value=0.2, case="C3"),
    data.frame(algo="A1", value=0.2, case="C4"),
    data.frame(algo="A2", value=1.0, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"),
    data.frame(algo="A2", value=1.0, case="C3"),
    data.frame(algo="A2", value=1.0, case="C4"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank(na.treat = "na.rm")

  expectedRanking <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("test-then-rank works for multi-task data set with no missing data", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A1", value=0.2, case="C3"),
                       data.frame(algo="A1", value=0.2, case="C4"),
                       data.frame(algo="A2", value=1.0, case="C1"),
                       data.frame(algo="A2", value=1.0, case="C2"),
                       data.frame(algo="A2", value=1.0, case="C3"),
                       data.frame(algo="A2", value=1.0, case="C4")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank()

  expectedRankingTask1 <- rbind(
    "A1" = data.frame(prop_significance = 1, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 2))

  expectedRankingTask2 <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRankingTask1)
  expect_equal(ranking$matlist$T2, expectedRankingTask2)
})

test_that("NAs are replaced by numeric value in multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=NA, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A1", value=0.2, case="C3"),
                       data.frame(algo="A1", value=0.2, case="C4"),
                       data.frame(algo="A2", value=1.0, case="C1"),
                       data.frame(algo="A2", value=1.0, case="C2"),
                       data.frame(algo="A2", value=1.0, case="C3"),
                       data.frame(algo="A2", value=1.0, case="C4")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%testThenRank(na.treat = 0)

  expectedRankingTask1 <- rbind(
    "A1" = data.frame(prop_significance = 1, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 2))

  expectedRankingTask2 <- rbind(
    "A1" = data.frame(prop_significance = 0, rank = 1),
    "A2" = data.frame(prop_significance = 0, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRankingTask1)
  expect_equal(ranking$matlist$T2, expectedRankingTask2)
})

test_that("test-then-rank raises error when no NA treatment specified but NAs are contained in multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A1", value=0.2, case="C3"),
                       data.frame(algo="A1", value=0.2, case="C4"),
                       data.frame(algo="A2", value=1.0, case="C1"),
                       data.frame(algo="A2", value=1.0, case="C2"),
                       data.frame(algo="A2", value=1.0, case="C3"),
                       data.frame(algo="A2", value=1.0, case="C4")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%testThenRank(),
               "argument \"na.treat\" is missing, with no default", fixed = TRUE)
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-rankingHeatmap.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("ranking heatmap for single-task data set has no title", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  actualPlot <- rankingHeatmap(ranking)
  expect_is(actualPlot, "ggplot")
  expect_equal(actualPlot$labels$title, NULL)
})

test_that("ranking heatmap for multi-task data set have titles", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
   dataTask2 <- cbind(task="T2",
                      rbind(
                        data.frame(algo="A1", value=0.2, case="C1"),
                        data.frame(algo="A2", value=0.3, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.7, case="C2"),
                        data.frame(algo="A2", value=0.8, case="C2"),
                        data.frame(algo="A3", value=0.9, case="C2")
                      ))

   data <- rbind(dataTask1, dataTask2)

   challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

   ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

   actualPlots <- rankingHeatmap(ranking)
   actualPlotTask1 <- actualPlots[[1]]
   actualPlotTask2 <- actualPlots[[2]]

   expect_is(actualPlotTask1, "ggplot")
   expect_equal(actualPlotTask1$labels$title, "T1")

   expect_is(actualPlotTask2, "ggplot")
   expect_equal(actualPlotTask2$labels$title, "T2")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-stackedFrequencyPlotStabilityByAlgorithm.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("stacked frequency plot for visualizing ranking stability by algorithm raises error for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  expect_error(stabilityByAlgorithm(rankingBootstrapped, stacked = TRUE),
               "The stability of rankings by algorithm cannot be computed for less than two tasks.", fixed=TRUE)
})

test_that("stacked frequency plot for visualizing ranking stability by algorithm returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, stacked = TRUE)
  expect_is(actualPlot, "ggplot")
})

test_that("stacked frequency plot for visualizing ranking stability by algorithm returns a plot for each algorithm", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), stacked = TRUE, single = TRUE)
  expect_equal(length(actualPlot), 3)
  expect_is(actualPlot[[1]], "ggplot")
  expect_is(actualPlot[[2]], "ggplot")
  expect_is(actualPlot[[3]], "ggplot")
})

test_that("stacked frequency plot for visualizing ranking stability by algorithm returns one plot if #algorithms equals #tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), stacked = TRUE, single = FALSE)
  expect_is(actualPlot, "ggplot")
})

test_that("stacked frequency plot for visualizing ranking stability by algorithm returns one plot if #algorithms < #tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.8, case="C2"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.3, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1"),
                       data.frame(algo="A1", value=0.1, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), stacked = TRUE, single = FALSE)
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-rankThenAggregate.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("rank-then-aggregate by mean works with two algorithms for one case, small values are better", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 1, rank = 1),
    "A2" = data.frame(rank_mean = 2, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate by mean works with two algorithms for one case, large values are better", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 2, rank = 2),
    "A2" = data.frame(rank_mean = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate raises error for invalid aggregation function", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%rankThenAggregate(FUN = meanx),
               "object 'meanx' not found", fixed = TRUE)
})

test_that("rank-then-aggregate by mean works with two algorithms for one case and 'min' as ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean, ties.method = "min")

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 1, rank = 1),
    "A2" = data.frame(rank_mean = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate by mean works with two algorithms for one case and 'max' as ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean, ties.method = "max")

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 2, rank = 2),
    "A2" = data.frame(rank_mean = 2, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate raises error for invalid ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%rankThenAggregate(FUN = mean, ties.method = "maxx"),
               "'arg' should be one of", fixed = TRUE)
})

test_that("rank-then-aggregate raises error for invalid ties method even when no ties present", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%rankThenAggregate(FUN = mean, ties.method = "maxx"),
               "'arg' should be one of", fixed = TRUE)
})

test_that("rank-then-aggregate by mean works with two algorithms for two cases", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A1", value=0.4, case="C2"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 1, rank = 1),
    "A2" = data.frame(rank_mean = 2, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate by median works with two algorithms for two cases", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A1", value=0.4, case="C2"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = median)

  expectedRanking <- rbind(
    "A1" = data.frame(rank_median = 1, rank = 1),
    "A2" = data.frame(rank_median = 2, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate by mean works with one algorithm for one case", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate assigns worst rank for NA", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(rank_mean = 2, rank = 2),
    "A2" = data.frame(rank_mean = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("rank-then-aggregate raises error for unused NA treatment argument", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  expect_error(challenge%>%rankThenAggregate(FUN = mean, na.treat = 0),
               "unused argument (na.treat = 0)", fixed = TRUE)
})

test_that("rank-then-aggregate by mean works for multi-task challenge (2 tasks in data set), no missing data", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.5, case="C1"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRankingTask1 <- rbind(
    "A1" = data.frame(rank_mean = 1, rank = 1),
    "A2" = data.frame(rank_mean = 2, rank = 2))

  expectedRankingTask2 <- rbind(
    "A1" = data.frame(rank_mean = 2, rank = 2),
    "A2" = data.frame(rank_mean = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRankingTask1)
  expect_equal(ranking$matlist$T2, expectedRankingTask2)
})

test_that("rank-then-aggregate assigns worst rank for NA in multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%rankThenAggregate(FUN = mean)

  expectedRankingTask1 <- rbind(
    "A1" = data.frame(rank_mean = 1, rank = 1),
    "A2" = data.frame(rank_mean = 2, rank = 2))

  expectedRankingTask2 <- rbind(
    "A1" = data.frame(rank_mean = 2, rank = 2),
    "A2" = data.frame(rank_mean = 1, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRankingTask1)
  expect_equal(ranking$matlist$T2, expectedRankingTask2)
})

test_that("rank-then-aggregate raises error for unused NA treatment argument in multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%rankThenAggregate(FUN = mean, na.treat = "na.rm"),
               "unused argument (na.treat = \"na.rm\")", fixed = TRUE)
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-taskSubset.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("extraction of task subset works for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  rankingSubset <- subset(ranking, tasks=c("T2"))

  expect_equal(length(rankingSubset$matlist), 1)
  expect_is(rankingSubset$matlist$T2, "data.frame")

  expect_equal(length(rankingSubset$data), 1)
  expect_is(rankingSubset$data$T2, "data.frame")
})

test_that("extraction of task subset works for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  rankingSubset <- subset(ranking, tasks=c("T1"))

  expect_equal(length(rankingSubset$matlist), 1)
  expect_is(rankingSubset$matlist$T1, "data.frame")

  expect_equal(length(rankingSubset$data), 1)
  expect_is(rankingSubset$data$T1, "data.frame")
})

test_that("extraction of task subset raises an error for invalid task name", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  expect_error(subset(ranking, tasks=c("T1x")),
               "There is/are no task(s) called T1x.", fixed=TRUE)
})

test_that("extraction of task subset from bootstrap ranking works for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrappedSubset <- subset(rankingBootstrapped, tasks=c("T2"))

  expect_equal(length(rankingBootstrappedSubset$matlist), 1)
  expect_is(rankingBootstrappedSubset$matlist$T2, "data.frame")

  expect_equal(length(rankingBootstrappedSubset$data), 1)
  expect_is(rankingBootstrappedSubset$data$T2, "data.frame")

  expect_equal(length(rankingBootstrappedSubset$bootsrappedRanks), 1)
  expect_is(rankingBootstrappedSubset$bootsrappedRanks$T2, "data.frame")

  expect_equal(length(rankingBootstrappedSubset$bootsrappedAggregate), 1)
  expect_is(rankingBootstrappedSubset$bootsrappedAggregate$T2, "data.frame")
})

test_that("extraction of task subset from bootstrap ranking works for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrappedSubset <- subset(rankingBootstrapped, tasks=c("T1"))

  expect_equal(length(rankingBootstrappedSubset$matlist), 1)
  expect_is(rankingBootstrappedSubset$matlist$T1, "data.frame")

  expect_equal(length(rankingBootstrappedSubset$data), 1)
  expect_is(rankingBootstrappedSubset$data$T1, "data.frame")

  expect_equal(length(rankingBootstrappedSubset$bootsrappedRanks), 1)
  expect_is(rankingBootstrappedSubset$bootsrappedRanks$T1, "data.frame")

  expect_equal(length(rankingBootstrappedSubset$bootsrappedAggregate), 1)
  expect_is(rankingBootstrappedSubset$bootsrappedAggregate$T1, "data.frame")
})

test_that("extraction of task subset from bootstrap ranking raises an error for invalid task name", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  expect_error(subset(rankingBootstrapped, tasks=c("T1x")),
               "There is/are no task(s) called T1x.", fixed=TRUE)

})



# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-blobPlotStabilityAcrossTasks.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("blob plot for visualizing ranking stability across tasks raises error for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  expect_error(stability(ranking),
               "The stability of rankings across tasks cannot be computed for less than two tasks.", fixed=TRUE)
})

test_that("blob plot for visualizing ranking stability across tasks returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  actualPlot <- stability(ranking)
  expect_is(actualPlot, "ggplot")
})

test_that("blob plot for visualizing ranking stability across tasks returns one plot for multi-task data set when consensus ranking is given", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stability(ranking, ordering = names(meanRanks))
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-violinPlot.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("violin plot for visualizing ranking stability returns one plot for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- violin(rankingBootstrapped)
  expect_is(actualPlot, "ggplot")
})

test_that("violin plot for visualizing ranking stability returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- violin(rankingBootstrapped)
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-stackedBarPlotStabilityByAlgorithm.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("stacked bar plot for visualizing ranking stability by algorithm raises error for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  expect_error(stabilityByAlgorithm(rankingBootstrapped, stacked = TRUE),
               "The stability of rankings by algorithm cannot be computed for less than two tasks.", fixed=TRUE)
})

test_that("stacked bar plot for visualizing ranking stability by algorithm returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, stacked = TRUE)
  expect_is(actualPlot, "ggplot")
})

test_that("stacked bar plot for visualizing ranking stability by algorithm returns one plot if #algorithms equals #tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, stacked = TRUE)
  expect_is(actualPlot, "ggplot")
})

test_that("stacked bar plot for visualizing ranking stability by algorithm returns one plot if #algorithms < #tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.8, case="C2"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.3, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1"),
                       data.frame(algo="A1", value=0.1, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, stacked = TRUE)
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-boxplot.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("boxplot for ranked single-task data set has no title", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  actualPlot <- boxplot(ranking)
  expect_is(actualPlot, "ggplot")
  expect_equal(actualPlot$labels$title, NULL)
})

test_that("boxplots for ranked multi-task data set have titles", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
   dataTask2 <- cbind(task="T2",
                      rbind(
                        data.frame(algo="A1", value=0.2, case="C1"),
                        data.frame(algo="A2", value=0.3, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.7, case="C2"),
                        data.frame(algo="A2", value=0.8, case="C2"),
                        data.frame(algo="A3", value=0.9, case="C2")
                      ))

   data <- rbind(dataTask1, dataTask2)

   challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

   ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

   actualPlots <- boxplot(ranking)
   actualPlotTask1 <- actualPlots[[1]]
   actualPlotTask2 <- actualPlots[[2]]

   expect_is(actualPlotTask1, "ggplot")
   expect_equal(actualPlotTask1$labels$title, "T1")

   expect_is(actualPlotTask2, "ggplot")
   expect_equal(actualPlotTask2$labels$title, "T2")
})



# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-subset.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("top 2 performing algorithms are extracted and data set is reduced respectively", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  rankingSubset <- subset(ranking, top=2)

  expectedRankingSubset <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.35, rank = 2))

  expect_equal(rankingSubset$matlist$T1, expectedRankingSubset)

  expect_equal(as.vector(rankingSubset$data$T1$algo), c("A1", "A2", "A1", "A2"))
  expect_equal(as.vector(rankingSubset$data$T1$value), c(0.8, 0.6, 0.2, 0.1))
  expect_equal(as.vector(rankingSubset$data$T1$case), c("C1", "C1", "C2", "C2"))
  expect_equal(as.vector(rankingSubset$data$T1$task), c("T1", "T1", "T1", "T1"))

  # check that full data set is preserved
  expect_equal(rankingSubset$fulldata$T1, challenge$T1)
})

test_that("extraction of subset raises error for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  expect_error(subset(ranking, top=2),
               "Subset of algorithms only sensible for single-task challenges.", fixed=TRUE)
})

test_that("extraction of subset returns all algorithms even when more are requested", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  rankingSubset <- subset(ranking, top=4)

  expectedRankingSubset <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.35, rank = 2),
    "A3" = data.frame(value_mean = 0.2, rank = 3))

  expect_equal(rankingSubset$matlist$T1, expectedRankingSubset)
})

test_that("extraction of subset returns more algorithms then requested when ties are present", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A3", value=0.8, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.2, case="C2"),
    data.frame(algo="A3", value=0.2, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  rankingSubset <- subset(ranking, top=2)

  expectedRankingSubset <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.5, rank = 1),
    "A3" = data.frame(value_mean = 0.5, rank = 1))

  expect_equal(rankingSubset$matlist$T1, expectedRankingSubset)
})

test_that("top 2 performing algorithms are extracted from bootstrap ranking and data set is reduced respectively", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrappedSubset <- subset(rankingBootstrapped, top=2)

  expectedRankingSubset <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.35, rank = 2))

  expect_equal(rankingBootstrappedSubset$matlist$T1, expectedRankingSubset)

  expect_equal(as.vector(rankingBootstrappedSubset$data$T1$algo), c("A1", "A2", "A1", "A2"))
  expect_equal(as.vector(rankingBootstrappedSubset$data$T1$value), c(0.8, 0.6, 0.2, 0.1))
  expect_equal(as.vector(rankingBootstrappedSubset$data$T1$case), c("C1", "C1", "C2", "C2"))
  expect_equal(as.vector(rankingBootstrappedSubset$data$T1$task), c("T1", "T1", "T1", "T1"))

  expect_equal(dim(rankingBootstrappedSubset$bootsrappedRanks$T1), c(2, 10))
  expect_equal(dim(rankingBootstrappedSubset$bootsrappedAggregate$T1), c(2, 10))

  # check that full data set is preserved
  expect_equal(rankingBootstrappedSubset$fulldata$T1, challenge$T1)
})

test_that("extraction of bootstrap ranking subset raises error for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  expect_error(subset(subset(rankingBootstrapped, top=2), top=2),
               "Subset of algorithms only sensible for single-task challenges.", fixed=TRUE)
})

test_that("extraction of bootstrap ranking subset returns all algorithms even when more are requested", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrappedSubset <- subset(rankingBootstrapped, top=4)

  expectedRankingSubset <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.35, rank = 2),
    "A3" = data.frame(value_mean = 0.2, rank = 3))

  expect_equal(rankingBootstrappedSubset$matlist$T1, expectedRankingSubset)
})

test_that("extraction of bootstrap ranking subset returns more algorithms then requested when ties are present", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A3", value=0.8, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.2, case="C2"),
    data.frame(algo="A3", value=0.2, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=mean, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrappedSubset <- subset(rankingBootstrapped, top=2)

  expectedRankingSubset <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.5, rank = 1),
    "A3" = data.frame(value_mean = 0.5, rank = 1))

  expect_equal(rankingBootstrappedSubset$matlist$T1, expectedRankingSubset)
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-report.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("PDF report for single-task data set without bootstrapping is created", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  ranking %>%
    report(title="Test Challenge",
           file="testthat_single_task_no_bootstrapping",
           format="PDF",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_single_task_no_bootstrapping.pdf"))

  # Clean up
  if (file.exists("testthat_single_task_no_bootstrapping.pdf")) {
    file.remove("testthat_single_task_no_bootstrapping.pdf")
  }

})

test_that("HTML report for single-task data set without bootstrapping is created", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  ranking %>%
    report(title="Test Challenge",
           file="testthat_single_task_no_bootstrapping",
           format="HTML",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_single_task_no_bootstrapping.html"))

  # Clean up
  if (file.exists("testthat_single_task_no_bootstrapping.html")) {
    file.remove("testthat_single_task_no_bootstrapping.html")
  }

})

test_that("Word report for single-task data set without bootstrapping is created", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  ranking %>%
    report(title="Test Challenge",
           file="testthat_single_task_no_bootstrapping",
           format="Word",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_single_task_no_bootstrapping.docx"))

  # Clean up
  if (file.exists("testthat_single_task_no_bootstrapping.docx")) {
    file.remove("testthat_single_task_no_bootstrapping.docx")
  }

})

test_that("PDF report for single-task data set with bootstrapping is created", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(title="Test Challenge",
           file="testthat_single_task_bootstrapping",
           format="PDF",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_single_task_bootstrapping.pdf"))

  # Clean up
  if (file.exists("testthat_single_task_bootstrapping.pdf")) {
    file.remove("testthat_single_task_bootstrapping.pdf")
  }

})

test_that("HTML report for single-task data set with bootstrapping is created", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(title="Test Challenge",
           file="testthat_single_task_bootstrapping",
           format="HTML",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_single_task_bootstrapping.html"))

  # Clean up
  if (file.exists("testthat_single_task_bootstrapping.html")) {
    file.remove("testthat_single_task_bootstrapping.html")
  }

})

test_that("Word report for single-task data set with bootstrapping is created", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(title="Test Challenge",
           file="testthat_single_task_bootstrapping",
           format="Word",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_single_task_bootstrapping.docx"))

  # Clean up
  if (file.exists("testthat_single_task_bootstrapping.docx")) {
    file.remove("testthat_single_task_bootstrapping.docx")
  }

})

test_that("PDF report for multi-task data set without bootstrapping is created", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  ranking %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_no_bootstrapping",
           format="PDF",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_no_bootstrapping.pdf"))

  # Clean up
  if (file.exists("testthat_multi_task_no_bootstrapping.pdf")) {
    file.remove("testthat_multi_task_no_bootstrapping.pdf")
  }

})

test_that("HTML report for multi-task data set without bootstrapping is created", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  ranking %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_no_bootstrapping",
           format="HTML",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_no_bootstrapping.html"))

  # Clean up
  if (file.exists("testthat_multi_task_no_bootstrapping.html")) {
    file.remove("testthat_multi_task_no_bootstrapping.html")
  }

})

test_that("Word report for multi-task data set without bootstrapping is created", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  ranking %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_no_bootstrapping",
           format="Word",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_no_bootstrapping.docx"))

  # Clean up
  if (file.exists("testthat_multi_task_no_bootstrapping.docx")) {
    file.remove("testthat_multi_task_no_bootstrapping.docx")
  }

})

test_that("PDF report for multi-task data set with bootstrapping is created", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.2, case="C1"),
                       data.frame(algo="A3", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.7, case="C2"),
                       data.frame(algo="A3", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_bootstrapping",
           format="PDF",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_bootstrapping.pdf"))

  # Clean up
  if (file.exists("testthat_multi_task_bootstrapping.pdf")) {
    file.remove("testthat_multi_task_bootstrapping.pdf")
  }

})

test_that("HTML report for multi-task data set with bootstrapping is created", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.2, case="C1"),
                       data.frame(algo="A3", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.7, case="C2"),
                       data.frame(algo="A3", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_bootstrapping",
           format="HTML",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_bootstrapping.html"))

  # Clean up
  if (file.exists("testthat_multi_task_bootstrapping.html")) {
    file.remove("testthat_multi_task_bootstrapping.html")
  }

})

test_that("Word report for multi-task data set with bootstrapping is created", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.2, case="C1"),
                       data.frame(algo="A3", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.7, case="C2"),
                       data.frame(algo="A3", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_bootstrapping",
           format="Word",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_bootstrapping.docx"))

  # Clean up
  if (file.exists("testthat_multi_task_bootstrapping.docx")) {
    file.remove("testthat_multi_task_bootstrapping.docx")
  }

})

test_that("PDF report for multi-task data set with bootstrapping is created (#algorithms < #tasks)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.80, case="C1"),
                       data.frame(algo="A2", value=0.60, case="C1"),
                       data.frame(algo="A1", value=0.85, case="C2"),
                       data.frame(algo="A2", value=0.65, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.20, case="C1"),
                       data.frame(algo="A2", value=0.30, case="C1"),
                       data.frame(algo="A1", value=0.25, case="C2"),
                       data.frame(algo="A2", value=0.35, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.10, case="C1"),
                       data.frame(algo="A2", value=0.80, case="C1"),
                       data.frame(algo="A1", value=0.15, case="C2"),
                       data.frame(algo="A2", value=0.85, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  meanRanks <- ranking%>%consensus(method = "euclidean")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  rankingBootstrapped %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_multi_task_bootstrapping_more_tasks_than_algorithms",
           format="PDF",
           clean=TRUE,
           open=FALSE)

  expect_true(file.exists("testthat_multi_task_bootstrapping_more_tasks_than_algorithms.pdf"))

  # Clean up
  if (file.exists("testthat_multi_task_bootstrapping_more_tasks_than_algorithms.pdf")) {
    file.remove("testthat_multi_task_bootstrapping_more_tasks_than_algorithms.pdf")
  }

})



test_that("PDF report is created when all metric values are identical", {
  n <- 10
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1",value=rep(1,n,),case=as.character(1:n)),
                       data.frame(algo="A2",value=rep(1,n,),case=as.character(1:n))
                       ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.20, case="C1"),
                       data.frame(algo="A2", value=0.30, case="C1"),
                       data.frame(algo="A1", value=0.25, case="C2"),
                       data.frame(algo="A2", value=0.35, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.10, case="C1"),
                       data.frame(algo="A2", value=0.80, case="C1"),
                       data.frame(algo="A1", value=0.15, case="C2"),
                       data.frame(algo="A2", value=0.85, case="C2")
                     ))
  
  data <- rbind(dataTask1, dataTask2, dataTask3)
  
  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)
  
  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")
  
  meanRanks <- ranking%>%consensus(method = "euclidean")
  
  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=3)
  
  rankingBootstrapped %>%
    report(consensus=meanRanks,
           title="Test Challenge",
           file="testthat_allMetricValues_identical",
           format="PDF",
           clean=TRUE,
           open=FALSE)
  
  expect_true(file.exists("testthat_allMetricValues_identical.pdf"))
  
  # Clean up
  if (file.exists("testthat_allMetricValues_identical.pdf")) {
    file.remove("testthat_allMetricValues_identical.pdf")
  }
  
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-aggregateThenRank.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("aggregate-then-rank by mean works with two algorithms for one case, small values are better", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 1),
    "A2" = data.frame(value_mean = 0.8, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank by mean works with two algorithms for one case, large values are better", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 2),
    "A2" = data.frame(value_mean = 0.8, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank raises error for invalid aggregation function", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%aggregateThenRank(FUN = meanx),
               "object 'meanx' not found", fixed = TRUE)
})

test_that("aggregate-then-rank by mean works with two algorithms for one case and 'min' as ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, ties.method = "min")

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 1),
    "A2" = data.frame(value_mean = 0.6, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank by mean works with two algorithms for one case and 'max' as ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, ties.method = "max")

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 2),
    "A2" = data.frame(value_mean = 0.6, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank raises error for invalid ties method", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%aggregateThenRank(FUN = mean, ties.method = "maxx"),
               "'arg' should be one of", fixed = TRUE)
})

test_that("aggregate-then-rank raises error for invalid ties method even when no ties present", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%aggregateThenRank(FUN = mean, ties.method = "maxx"),
               "'arg' should be one of", fixed = TRUE)
})

test_that("aggregate-then-rank by mean works with two algorithms for two cases", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A1", value=0.4, case="C2"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 1),
    "A2" = data.frame(value_mean = 0.9, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank by median works with two algorithms for two cases", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A1", value=0.4, case="C2"),
    data.frame(algo="A2", value=0.8, case="C1"),
    data.frame(algo="A2", value=1.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = median)

  expectedRanking <- rbind(
    "A1" = data.frame(value_median = 0.5, rank = 1),
    "A2" = data.frame(value_median = 0.9, rank = 2))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank by mean works with one algorithm for one case", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank raises error when no NA treatment specified but NAs are contained", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  expect_error(challenge%>%aggregateThenRank(FUN = mean),
               "argument \"na.treat\" is missing, with no default", fixed = TRUE)
})

test_that("aggregate-then-rank raises error when invalid NA treatment specified and NAs are contained", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  expect_error(challenge%>%aggregateThenRank(FUN = mean, na.treat = "na.rmx"),
               "Argument 'na.treat' is invalid. It can be 'na.rm', numeric value or function.", fixed = TRUE)
})

test_that("specified NA treatment does not influence ranking when no NAs are contained", {
  data <- rbind(
    data.frame(algo="A1", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, na.treat = 0)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 2),
    "A2" = data.frame(value_mean = 0.8, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("NAs are replaced by numeric value", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, na.treat = 0)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = 0.0, rank = 2),
    "A2" = data.frame(value_mean = 0.8, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("NAs are replaced by function value", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  replacementFunction <- function(x) { -1 }

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, na.treat = replacementFunction)

  expectedRanking <- rbind(
    "A1" = data.frame(value_mean = -1.0, rank = 2),
    "A2" = data.frame(value_mean = 0.8, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("NAs are removed", {
  data <- rbind(
    data.frame(algo="A1", value=NA, case="C1"),
    data.frame(algo="A2", value=0.8, case="C1"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter = FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, na.treat = "na.rm")

  expectedRanking <- rbind(
    "A2" = data.frame(value_mean = 0.8, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRanking)
})

test_that("aggregate-then-rank by mean works for multi-task challenge (2 tasks in data set), no missing data", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.5, case="C1"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean)

  expectedRankingTask1 <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 1),
    "A2" = data.frame(value_mean = 0.8, rank = 2))

  expectedRankingTask2 <- rbind(
    "A1" = data.frame(value_mean = 0.5, rank = 2),
    "A2" = data.frame(value_mean = 0.4, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRankingTask1)
  expect_equal(ranking$matlist$T2, expectedRankingTask2)
})

test_that("NAs are replaced by numeric value in multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  ranking <- challenge%>%aggregateThenRank(FUN = mean, na.treat = 100)

  expectedRankingTask1 <- rbind(
    "A1" = data.frame(value_mean = 0.6, rank = 1),
    "A2" = data.frame(value_mean = 0.8, rank = 2))

  expectedRankingTask2 <- rbind(
    "A1" = data.frame(value_mean = 100.0, rank = 2),
    "A2" = data.frame(value_mean = 0.4, rank = 1))

  expect_equal(ranking$matlist$T1, expectedRankingTask1)
  expect_equal(ranking$matlist$T2, expectedRankingTask2)
})

test_that("aggregate-then-rank raises error when no NA treatment specified but NAs are contained in multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.6, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter = TRUE)

  expect_error(challenge%>%aggregateThenRank(FUN = mean),
               "argument \"na.treat\" is missing, with no default", fixed = TRUE)
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-challenge.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("empty attribute 'taskName' raises error for single-task challenge", {
  data <- rbind(
      data.frame(algo="A1", value=0.8, case="C1"),
      data.frame(algo="A2", value=0.6, case="C1"))

  expect_error(as.challenge(data, taskName="", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "Argument 'taskName' is empty.", fixed=TRUE)
})

test_that("only whitespaces in attribute 'taskName' raises error for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  expect_error(as.challenge(data, taskName="  ", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "Argument 'taskName' is empty.", fixed=TRUE)
})

test_that("attributes are set for single-task challenge with specified task name", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  expect_equal(attr(actualChallenge, "annotator"), NULL)
  expect_equal(attr(actualChallenge, "by"), "task")
  expect_equal(attr(actualChallenge, "smallBetter"), FALSE)
  expect_equal(attr(actualChallenge, "check"), TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C1"))
  expect_equal(as.vector(actualChallenge$T1$task), c("T1", "T1"))

  # expect that there's no attribute "task"
  expect_equal(attr(actualChallenge, "task"), NULL)
  expect_equal(attr(actualChallenge$T1, "task"), NULL)
  expect_equal(attr(actualChallenge$T2, "task"), NULL)
})

test_that("attributes are set for single-task challenge with dummy task name", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  actualChallenge <- as.challenge(data, algorithm="algo", case="case", value="value", smallBetter=FALSE)

  expect_equal(attr(actualChallenge, "annotator"), NULL)
  expect_equal(attr(actualChallenge, "by"), "task")
  expect_equal(attr(actualChallenge, "smallBetter"), FALSE)
  expect_equal(attr(actualChallenge, "check"), TRUE)

  expect_equal(as.vector(actualChallenge$dummyTask$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$dummyTask$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$dummyTask$case), c("C1", "C1"))
  expect_equal(as.vector(actualChallenge$dummyTask$task), c("dummyTask", "dummyTask"))

  # expect that there's no attribute "task"
  expect_equal(attr(actualChallenge, "task"), NULL)
  expect_equal(attr(actualChallenge$dummyTask, "task"), NULL)
  expect_equal(attr(actualChallenge$dummyTask, "task"), NULL)
})

test_that("leading and trailing whitespaces are trimmed for attribute 'taskName'", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"))

  actualChallenge <- as.challenge(data, taskName=" T1  ", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A2"))
})

test_that("attributes are set for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=TRUE)

  expect_equal(attr(actualChallenge, "annotator"), NULL)
  expect_equal(attr(actualChallenge, "by"), "task")
  expect_equal(attr(actualChallenge, "smallBetter"), TRUE)
  expect_equal(attr(actualChallenge, "check"), TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C1"))
  expect_equal(as.vector(actualChallenge$T1$task), c("T1", "T1"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(0.2, 0.3))
  expect_equal(as.vector(actualChallenge$T2$case), c("C1", "C1"))
  expect_equal(as.vector(actualChallenge$T2$task), c("T2", "T2"))

  # expect that there's no attribute "task"
  expect_equal(attr(actualChallenge, "task"), NULL)
  expect_equal(attr(actualChallenge$T1, "task"), NULL)
  expect_equal(attr(actualChallenge$T2, "task"), NULL)
})

test_that("attributes are set for multi-task challenge with sanity check disabled", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=TRUE, check=FALSE)

  expect_equal(attr(actualChallenge, "annotator"), NULL)
  expect_equal(attr(actualChallenge, "by"), "task")
  expect_equal(attr(actualChallenge, "smallBetter"), TRUE)
  expect_equal(attr(actualChallenge, "check"), FALSE)
  expect_equal(as.vector(actualChallenge$algo), c("A1", "A2", "A1", "A2"))
  expect_equal(as.vector(actualChallenge$value), c(0.8, 0.6, 0.2, 0.3))
  expect_equal(as.vector(actualChallenge$case), c("C1", "C1", "C1", "C1"))
  expect_equal(as.vector(actualChallenge$task), c("T1", "T1", "T2", "T2"))
})

test_that("attribute 'taskName' is ignored for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  expect_warning(as.challenge(data, taskName="T1", by="task", algorithm="algo", case="case", value="value", smallBetter=TRUE),
                 "Argument 'taskName' is ignored for multi-task data set.", fixed=TRUE)
})

test_that("missing algorithm performances are added as NAs for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C2"))

  expect_message(actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE),
                 "Performance of not all algorithms has been observed for all cases.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, NA, NA, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))
  expect_equal(as.vector(actualChallenge$T1$task), c("T1", "T1", "T1", "T1"))
})

test_that("multi-task data set containing one task is interpreted as single-task data set, missing algorithm performances are added", {
  data <- cbind(task="T1",
                rbind(
                  data.frame(algo="A1", value=0.8, case="C1"),
                  data.frame(algo="A2", value=0.6, case="C2")
                ))

  # do not specify parameter "by" to interpret multi-task data set as single-task data set
  expect_message(actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE),
                 "Performance of not all algorithms has been observed for all cases.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, NA, NA, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))
})

test_that("missing algorithm performances are added as NAs for multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A1", value=0.3, case="C2"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  expect_message(actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE),
                 "Performance of not all algorithms has been observed for all cases in task 'T1'.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, NA, NA, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))
  expect_equal(as.vector(actualChallenge$T1$task), c("T1", "T1", "T1", "T1"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(0.2, 0.3, 0.4, NA))
  expect_equal(as.vector(actualChallenge$T2$case), c("C1", "C2", "C1", "C2"))
  expect_equal(as.vector(actualChallenge$T2$task), c("T2", "T2", "T2", "T2"))
})

test_that("missing algorithm performances are not added as NA with sanity check disabled for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C2"))

  actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, check=FALSE)

  expect_equal(as.vector(actualChallenge$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$case), c("C1", "C2"))
})

test_that("missing algorithm performances are not added as NA with sanity check disabled for multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A1", value=0.3, case="C2"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE, check=FALSE)

  expect_equal(as.vector(actualChallenge$algo), c("A1", "A2", "A1", "A1", "A2"))
  expect_equal(as.vector(actualChallenge$value), c(0.8, 0.6, 0.2, 0.3, 0.4))
  expect_equal(as.vector(actualChallenge$case), c("C1", "C2", "C1", "C2", "C1"))
})

test_that("case cannot appear more than once per algorithm for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=0.8, case="C1"))

  expect_error(as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1", fixed=TRUE)
})

test_that("multi-task data set containing one task is interpreted as single-task data set, case cannot appear more than once per algorithm", {
  data <- cbind(task="T1",
                rbind(
                  data.frame(algo="A1", value=0.8, case="C1"),
                  data.frame(algo="A1", value=0.8, case="C1")
                ))

  # do not specify parameter "by" to interpret multi-task data set as single-task data set
  expect_error(as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1", fixed=TRUE)
})

test_that("case cannot appear more than once per algorithm for multi-task challenge (1 task in data set)", {
  data <- cbind(task="T1",
                rbind(
                  data.frame(algo="A1", value=0.8, case="C1"),
                  data.frame(algo="A1", value=0.8, case="C1")
                ))

  expect_error(as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1", fixed=TRUE)
})

test_that("cases cannot appear more than once per algorithm for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.7, case="C1"),
    data.frame(algo="A1", value=0.5, case="C2"),
    data.frame(algo="A2", value=0.6, case="C2"),
    data.frame(algo="A2", value=0.6, case="C2"))

  expect_error(as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1, C2", fixed=TRUE)
})

test_that("cases cannot appear more than once per algorithm for multi-task challenge (1 task in data set)", {
  data <- cbind(task="T1",
                rbind(
                  data.frame(algo="A1", value=0.8, case="C1"),
                  data.frame(algo="A1", value=0.8, case="C1"),
                  data.frame(algo="A2", value=0.7, case="C1"),
                  data.frame(algo="A1", value=0.5, case="C2"),
                  data.frame(algo="A2", value=0.6, case="C2"),
                  data.frame(algo="A2", value=0.6, case="C2")
                ))

  expect_error(as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1, C2", fixed=TRUE)
})

test_that("cases cannot appear more than once per algorithm for multi-task challenge (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1") # let T1 pass
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.7, case="C1"),
                       data.frame(algo="A1", value=0.5, case="C2"),
                       data.frame(algo="A2", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  expect_error(as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm in task 'T2'. Please revise.\nCase(s): C1, C2", fixed=TRUE)
})

test_that("cases cannot appear more than once per algorithm when missing data was added for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C2"),
    data.frame(algo="A2", value=0.6, case="C2"))

  expect_error(as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1, C2", fixed=TRUE)
})

test_that("user is notified of duplicate cases when multi-task data set is interpreted as single-task data set (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  # do not specify parameter "by" to interpret multi-task data set as single-task data set
  expect_error(as.challenge(data, taskName="New task", algorithm="algo", case="case", value="value", smallBetter=FALSE),
               "The following case(s) appear(s) more than once for the same algorithm. Please revise. Or are you considering a multi-task challenge and forgot to specify argument 'by'?\nCase(s): C1", fixed=TRUE)
})

test_that("user is notified of missing algorithm performance when multi-task data set is interpreted as single-task data set (2 tasks in data set)", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1")
                     ))

  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  # do not specify parameter "by" to interpret multi-task data set as single-task data set
  expect_message(as.challenge(data, taskName="New task", algorithm="algo", case="case", value="value", smallBetter=FALSE),
                 "Performance of not all algorithms has been observed for all cases.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)
})

test_that("NAs are replaced by numeric value for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=NA, case="C2"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A2", value=NA, case="C2"))

  actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=0)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.0, 0.6, 0.0))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))
})

test_that("NAs are replaced by numeric value for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A1", value=NA, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A2", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.5, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=0)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.0))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A2", "A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(0.0, 0.5))
  expect_equal(as.vector(actualChallenge$T2$case), c("C1", "C2"))
})

test_that("NAs are replaced by function value for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=NA, case="C2"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A2", value=NA, case="C2"))

  replacementFunction <- function(x) { 2 }

  actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=replacementFunction)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 2.0, 0.6, 2.0))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))
})

test_that("NAs are replaced by function value for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A1", value=NA, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A2", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.5, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  replacementFunction <- function(x) { 2 }

  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=replacementFunction)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 2.0))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A2", "A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(2.0, 0.5))
  expect_equal(as.vector(actualChallenge$T2$case), c("C1", "C2"))
})

test_that("NAs are removed for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=NA, case="C2"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A2", value=NA, case="C2"))

  actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat="na.rm")

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C1"))
})

test_that("NAs are removed for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A1", value=NA, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A2", value=NA, case="C1"),
                       data.frame(algo="A2", value=0.5, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat="na.rm")

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(0.5))
  expect_equal(as.vector(actualChallenge$T2$case), c("C2"))
})

test_that("automatically added NAs are replaced by numeric value for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C2"))

  expect_message(actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=0),
                 "Performance of not all algorithms has been observed for all cases.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.0, 0.0, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))
})

test_that("automatically added NAs are replaced by numeric value for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A1", value=0.3, case="C2"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  expect_message(actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=0),
                 "Performance of not all algorithms has been observed for all cases in task 'T1'.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.0, 0.0, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2", "C1", "C2"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A1", "A1", "A2", "A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(0.2, 0.3, 0.4, 0.0))
  expect_equal(as.vector(actualChallenge$T2$case), c("C1", "C2", "C1", "C2"))
})

test_that("automatically added NAs are removed for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C2"))

  expect_message(actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat="na.rm"),
                 "Performance of not all algorithms has been observed for all cases.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2"))
})

test_that("automatically added NAs are removed for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A1", value=0.3, case="C2"),
                       data.frame(algo="A2", value=0.4, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2)

  expect_message(actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat="na.rm"),
                 "Performance of not all algorithms has been observed for all cases in task 'T1'.\nTherefore, missings have been inserted in the following cases:", fixed=TRUE)

  expect_equal(as.vector(actualChallenge$T1$algo), c("A1", "A2"))
  expect_equal(as.vector(actualChallenge$T1$value), c(0.8, 0.6))
  expect_equal(as.vector(actualChallenge$T1$case), c("C1", "C2"))

  expect_equal(as.vector(actualChallenge$T2$algo), c("A1", "A1", "A2"))
  expect_equal(as.vector(actualChallenge$T2$value), c(0.2, 0.3, 0.4))
  expect_equal(as.vector(actualChallenge$T2$case), c("C1", "C2", "C1"))
})

test_that("class of 'algorithm' column must be 'factor' for single-task challenge", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A1", value=0.7, case="C2"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A2", value=0.5, case="C2"))
  
  actualChallenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE, na.treat=0)
  
  expect_equal(class(actualChallenge$T1$algo), "factor")
})  

test_that("class of 'algorithm' column must be 'factor' for multi-task challenge", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.81, case="C1"),
                       data.frame(algo="A2", value=0.72, case="C1"),
                       data.frame(algo="A1", value=0.65, case="C2"),
                       data.frame(algo="A2", value=0.95, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.75, case="C1"),
                       data.frame(algo="A2", value=0.82, case="C1"),
                       data.frame(algo="A1", value=0.66, case="C2"),
                       data.frame(algo="A2", value=0.84, case="C2")
                     ))
  
  data <- rbind(dataTask1, dataTask2)
  
  actualChallenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=TRUE)
  
  expect_equal(class(actualChallenge$T1$algo), "factor")
  expect_equal(class(actualChallenge$T2$algo), "factor")
})




# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-blobPlotStabilityByAlgorithm.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("blob plot for visualizing ranking stability by algorithm raises error for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  expect_error(stabilityByAlgorithm(rankingBootstrapped),
               "The stability of rankings by algorithm cannot be computed for less than two tasks.", fixed=TRUE)
})

test_that("blob plot for visualizing ranking stability by algorithm returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped)
  expect_is(actualPlot, "ggplot")
})

test_that("blob plot for visualizing ranking stability by algorithm returns a plot for each algorithm", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), single = TRUE)
  expect_equal(length(actualPlot), 3)
  expect_is(actualPlot[[1]], "ggplot")
  expect_is(actualPlot[[2]], "ggplot")
  expect_is(actualPlot[[3]], "ggplot")
})

test_that("Multi task bootstrapping, only one task with >1 test case stability plot works", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.3, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")
  rankingBootstrapped <- ranking%>%bootstrap(nboot=3)
  meanRanks <- ranking%>%consensus(method = "euclidean")
  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), single = FALSE)
  expect_is(actualPlot, "ggplot")
})

test_that("blob plot for visualizing ranking stability by algorithm returns one plot if #algorithms equals #tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), single = FALSE)
  expect_is(actualPlot, "ggplot")
})

test_that("blob plot for visualizing ranking stability by algorithm returns one plot if #algorithms < #tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A1", value=0.8, case="C2"),
                       data.frame(algo="A2", value=0.6, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.3, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1"),
                       data.frame(algo="A1", value=0.1, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  meanRanks <- ranking%>%consensus(method = "euclidean")

  actualPlot <- stabilityByAlgorithm(rankingBootstrapped, ordering = names(meanRanks), single = FALSE)
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-blobPlotStabilityByTask.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("blob plot for visualizing ranking stability returns one plot for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- stabilityByTask(rankingBootstrapped)
  expect_is(actualPlot, "ggplot")
})

test_that("blob plot for visualizing ranking stability returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  rankingBootstrapped <- ranking%>%bootstrap(nboot=10)

  actualPlot <- stabilityByTask(rankingBootstrapped)
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-bootstrap.R
test_that("single-task bootstrapping with 1 test case stopped with message", {
  dataTask1 <- cbind(task="T1",
                   rbind(
                     data.frame(algo="A1", value=0.8, case="C1"),
                     data.frame(algo="A2", value=0.6, case="C1")
                   ))


challenge <- as.challenge(dataTask1,  algorithm="algo", case="case", value="value", smallBetter=FALSE)

ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

set.seed(1)
expect_error(rankingBootstrapped <- ranking%>%bootstrap(nboot=10),
             "Only 1 test case included. Bootstrapping with 1 test case not sensible.", fixed = TRUE)
})


test_that("multi-task bootstrapping, all tasks with 1 test case stopped with message", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  expect_error(rankingBootstrapped <- ranking%>%bootstrap(nboot=10),
               "All tasks only contained 1 test case. Bootstrapping with 1 test case not sensible.", fixed = TRUE)
})


test_that("multi-task bootstrapping, only one task with >1 test case continued with message", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.3, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.8, case="C1")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  set.seed(1)
  expect_message(rankingBootstrapped <- ranking%>%bootstrap(nboot=3),
               "Task(s) T1, T3 with only 1 test case excluded from bootstrapping.", fixed = TRUE)
})


test_that("two sequential bootstrappings yield same results", {
  data <- read.csv(system.file("extdata", "data_matrix.csv", package="challengeR", mustWork=TRUE))

  challenge <- as.challenge(data, by="task", algorithm="alg_name", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%rankThenAggregate(FUN=mean, ties.method="min")

  set.seed(123, kind="L'Ecuyer-CMRG")
  rankingBootstrapped1 <- ranking%>%bootstrap(nboot=10)

  set.seed(123, kind="L'Ecuyer-CMRG")
  rankingBootstrapped2 <- ranking%>%bootstrap(nboot=10)

  expect_equal(rankingBootstrapped1, rankingBootstrapped2)
})


test_that("two parallel bootstrappings yield same results", {
  data <- read.csv(system.file("extdata", "data_matrix.csv", package="challengeR", mustWork=TRUE))

  challenge <- as.challenge(data, by="task", algorithm="alg_name", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%rankThenAggregate(FUN=mean, ties.method="min")

  library(doParallel)
  library(doRNG)
  numCores <- detectCores(logical=FALSE)
  registerDoParallel(cores=numCores)

  registerDoRNG(123)
  rankingBootstrapped1 <- ranking%>%bootstrap(nboot=10, parallel=TRUE, progress="none")

  registerDoRNG(123)
  rankingBootstrapped2 <- ranking%>%bootstrap(nboot=10, parallel=TRUE, progress="none")

  stopImplicitCluster()

  expect_equal(rankingBootstrapped1, rankingBootstrapped2)
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-networkPlot.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("cluster analysis network plot raises error for single-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  expect_error(network(ranking, edge.col=grDevices::grey.colors, edge.lwd=1, cols=NULL),
               "The cluster analysis is only sensible for more than two tasks.", fixed=TRUE)
})

test_that("cluster analysis network plot raises error for multi-task data set containing two tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  expect_error(network(ranking, edge.col=grDevices::grey.colors, edge.lwd=1, cols=NULL),
               "The cluster analysis is only sensible for more than two tasks.", fixed=TRUE)
})

test_that("cluster analysis network plot returns a network object for multi-task data set containing three tasks", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                        data.frame(algo="A1", value=0.8, case="C1"),
                        data.frame(algo="A2", value=0.6, case="C1"),
                        data.frame(algo="A3", value=0.4, case="C1"),
                        data.frame(algo="A1", value=0.2, case="C2"),
                        data.frame(algo="A2", value=0.1, case="C2"),
                        data.frame(algo="A3", value=0.0, case="C2")
                      ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))
  dataTask3 <- cbind(task="T3",
                     rbind(
                       data.frame(algo="A1", value=0.1, case="C1"),
                       data.frame(algo="A2", value=0.2, case="C1"),
                       data.frame(algo="A3", value=0.3, case="C1"),
                       data.frame(algo="A1", value=0.6, case="C2"),
                       data.frame(algo="A2", value=0.7, case="C2"),
                       data.frame(algo="A3", value=0.8, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2, dataTask3)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  ranking <- challenge%>%aggregateThenRank(FUN=median, ties.method="min")

  actualPlot <- network(ranking, edge.col=grDevices::grey.colors, edge.lwd=1, cols=NULL)
  expect_is(actualPlot, "network")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/tests/testthat/test-linePlot.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test_that("line plot across ranking methods returns one plot for multi-task data set", {
  data <- rbind(
    data.frame(algo="A1", value=0.8, case="C1"),
    data.frame(algo="A2", value=0.6, case="C1"),
    data.frame(algo="A3", value=0.4, case="C1"),
    data.frame(algo="A1", value=0.2, case="C2"),
    data.frame(algo="A2", value=0.1, case="C2"),
    data.frame(algo="A3", value=0.0, case="C2"))

  challenge <- as.challenge(data, taskName="T1", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  actualPlot <- methodsplot(challenge)
  expect_is(actualPlot, "ggplot")
})

test_that("line plot across ranking methods returns one plot for multi-task data set", {
  dataTask1 <- cbind(task="T1",
                     rbind(
                       data.frame(algo="A1", value=0.8, case="C1"),
                       data.frame(algo="A2", value=0.6, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.2, case="C2"),
                       data.frame(algo="A2", value=0.1, case="C2"),
                       data.frame(algo="A3", value=0.0, case="C2")
                     ))
  dataTask2 <- cbind(task="T2",
                     rbind(
                       data.frame(algo="A1", value=0.2, case="C1"),
                       data.frame(algo="A2", value=0.3, case="C1"),
                       data.frame(algo="A3", value=0.4, case="C1"),
                       data.frame(algo="A1", value=0.7, case="C2"),
                       data.frame(algo="A2", value=0.8, case="C2"),
                       data.frame(algo="A3", value=0.9, case="C2")
                     ))

  data <- rbind(dataTask1, dataTask2)

  challenge <- as.challenge(data, by="task", algorithm="algo", case="case", value="value", smallBetter=FALSE)

  actualPlot <- methodsplot(challenge)
  expect_is(actualPlot, "ggplot")
})


# FILE: /mnt/data/challengeR_extracted/challengeR/R/rrank.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

rank <- function(object,...) UseMethod("rank")
rank.default <- function(object, ...) base::rank(object,...)  #stats::aggregate

rank.challenge=function(object,
                        x,
                        ties.method="min",...){
  call=as.list(match.call())
  if (!is.null(attr(object,"annotator"))) {
    call2=call("Rank",
               object=call$object,
               x=attr(object,"value"),
               annotator=c(attr(object,"annotator")),
               ties.method=ties.method,
               smallBetter=attr(object,"smallBetter")
             )
    res1=do.call("Rank",list(object=object,
                             x=attr(object,"value"),
                             annotator=c(attr(object,"annotator")),
                             ties.method=ties.method,
                             smallBetter=attr(object,"smallBetter")
           ))

  } else {
    call2=call("Rank",
               object=call$object,
               x=attr(object,"value"),
               ties.method=ties.method,
               smallBetter=attr(object,"smallBetter")
             )
    res1=do.call("Rank",list(object=object,
                             x=attr(object,"value"),
                             ties.method=ties.method,
                             smallBetter=attr(object,"smallBetter")
           ))

  }

  res=list(FUN = . %>% (call2),
           call=list(call2),
           FUN.list=list("rank"),
           data=object,
           matlist=res1$matlist)

  class(res)=c("ranked.list",class(res))
  res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/aaggregate.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

test <- function(x,...) UseMethod("test")
test.default <- function(x, ...) stop("not implemented for this class")
test.challenge=function(x,...) aggregate.challenge(x=x,
                                                   FUN="significance",...)


#' Title
#'
#' @param x
#' @param FUN
#' @param na.treat
#' @param alpha
#' @param p.adjust.method
#' @param parallel
#' @param progress
#' @param ...
#'
#' @return
#' @export
#'
#' @examples
aggregate.challenge=function(x,
                             FUN=mean,
                             na.treat, #either "na.rm", numeric value or function
                             alpha=0.05, p.adjust.method="none",# only needed for significance
                             parallel=FALSE,
                             progress="none",...){
  call=as.list(match.call())
  if (missing(na.treat) && !is.null(attr(x,"na.treat"))) na.treat <- attr(x, "na.treat")

  if (missing(na.treat)){ #na.treat only optional if no missing values in data set
    if (!inherits(x,"list")){
      if (!any(is.na(x[,attr(x, "value")]))) na.treat="na.rm" # there are no missings so set na.treat by dummy "na.rm" has no effect
    } else {
      if (!any(sapply(x,
                      function(task) any(is.na(task[,attr(x, "value")]))))) na.treat="na.rm" # there are no missings so set na.treat by dummy "na.rm" has no effect
    }
  } else attr(x,"na.treat") <- na.treat

  res1=do.call("Aggregate",list(object=x,
                                x=attr(x,"value"),
                                algorithm=attr(x,"algorithm"),
                                FUN=call$FUN,
                                na.treat=na.treat,
                                parallel=parallel,
                                progress=progress,
                                case=attr(x,"case"),
                                alpha=alpha, p.adjust.method=p.adjust.method,
                                smallBetter=attr(x,"smallBetter") # only needed for significance
  ))

  call2=call("Aggregate",
             object=call$x,
             x=attr(x,"value"),
             algorithm=attr(x,"algorithm"),
             FUN=call$FUN,
             na.treat=na.treat,
             parallel=parallel,progress=progress,
             case=attr(x,"case"),
             alpha=alpha, p.adjust.method=p.adjust.method,
             smallBetter=attr(x,"smallBetter") # only needed for significance
  )

  if (inherits(x,"list")){
    res=list(FUN = . %>% (call2),
             call=list(call2),
             FUN.list=list(FUN),
             data=x,
             matlist=res1$matlist,
             isSignificance=res1$isSignificance)

    class(res)=c("aggregated.list",class(res))
  } else {
    res=list(FUN = . %>% (call2),
             call=list(call2),
             FUN.list=list(FUN),
             data=x,
             mat=res1$mat,
             isSignificance=res1$isSignificance)

    class(res)=c("aggregated",class(res))

  }
  res

}


aggregate.ranked.list <-function(x,
                                 FUN=mean,
                                 ...){
  call=match.call(expand.dots = F)
  call=call("aggregate.ranked.list",
            x=call$x,
            FUN=FUN)

  algorithm=attr(x$data,"algorithm")
  resmatlist=Aggregate.list(x$matlist,
                            x="rank",
                            algorithm=algorithm,
                            FUN=FUN,...)$matlist
  resmatlist=lapply(resmatlist,
                    function(z) as.data.frame(z))
  res=list(matlist=resmatlist,
           call=c(x$call,call),
           data=x$data,
           FUN =  . %>% (x$FUN) %>%  (call),
           FUN.list=c(x$FUN.list,FUN)
  )
  class(res)=c("aggregatedRanks.list",class(res))
  res

}


aggregate.bootstrap.list <-function(x,
                                    what="metric",
                                    FUN=mean,
                                    ...){
  call=match.call(expand.dots = T)
  if (is.character(FUN)) FUN=try(eval(parse(text=FUN)),
                                 silent = T)
  FUNname=as.character(call$FUN)

  if (!is.function(FUN)) stop("FUN has to be a function (possibly as character)")
  matlist=llply(1:length(x$bootsrappedRank),
                function(i.piece){
                  if (what=="ranks") xmean <- as.data.frame(apply(x$bootsrappedRank[[i.piece]],1,FUN=FUN))
                  else xmean <- as.data.frame(apply(x$bootsrappedAggregate[[i.piece]],1,FUN=FUN))
                  names(xmean)=paste0(what,"_",FUNname)
                 xmean
                })


  names(matlist)=names(x$bootsrappedRank)
  res=list(FUN = . %>% (call),
           call=list(call),
           data=x,
           matlist=matlist)

  class(res)=c("aggregated.list",class(res))
  res
}

aggregate.bootstrap<-function(x,what="metric",FUN=mean,
                              ...            ){
  call=match.call(expand.dots = T)
  if (is.character(FUN)) FUN=try(eval(parse(text=FUN)),silent = T)
  FUNname=as.character(call$FUN)

  if (!is.function(FUN)) stop("FUN has to be a function (possibly as character)")

  if (what=="ranks") xmean <- as.data.frame(apply(x$bootsrappedRank,
                                                  1,
                                                  FUN=FUN))
  else xmean <- as.data.frame(apply(x$bootsrappedAggregate,
                                    1,
                                    FUN=FUN))
  names(xmean)=paste0(what,"_",FUNname)
  res=list(FUN = . %>% (call),
           call=list(call),
           data=x,
           mat=xmean)

  class(res)=c("aggregated",class(res))
  res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/relation.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

relation_dissimilarity <- function(x,...) UseMethod("relation_dissimilarity")
relation_dissimilarity.default <- function(x, ...) relations::relation_dissimilarity(x,  ...) 

relation_dissimilarity.ranked.list=function(x,
                                            method=kendall,
                                            ...){  #method in kendall, spearmansFootrule, spearmansWeightedFootrule or any other function with two arguments
  tt=names(x$matlist)
  n.tt=length(tt)
  tau=matrix(NA,n.tt,n.tt)
  colnames(tau)=rownames(tau)=tt
  aa=melt(x,
          measure.vars="rank")
  for (i in 1:n.tt){
    for (j in 1:n.tt){
      temp=aa%>%
        filter(L1==as.character(tt[i]))%>% 
        right_join(aa%>%
                     filter(L1==as.character(tt[j])),
                   by="algorithm")
      tau[i,j]=method(temp$value.x,
                      temp$value.y) 
    }
  }
  
  if (method(1:2,1:2)==1 & method(2:1,1:2)==-1)  as.dist(1-tau)  #if two identical objects yield value of 1, method seems to be a correlation
  else as.dist(tau) #distance
}


as.relation.ranked.list=function(x,...){
 res= lapply(x$matlist,function(z){
    r=z[,"rank"]
    names(r)=rownames(z)
    as.relation(r)
  } )
 class(res)="relation_ensemble"
 res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/merge.list.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

merge.list=function(x,y,by="row.names",suffixes = c(".1",".2"),...){
  if (is.list(x) & is.list(y)){
    #if (!all.equal(names(x),names(y))) stop("list elements must have same names and lists must have same length")
    common.elements=intersect(names(x),names(y))

    res=lapply(common.elements, function(z){
      merge(x[[z]],y[[z]],by=by,suffixes=suffixes,...)
    })
    names(res)=common.elements
    res

  } else stop("Comparison of a list and a data.frame under construction")
}

quickmerge.list=function(x,y){
  if (is.list(x) & is.list(y)){
    #if (!all.equal(names(x),names(y))) stop("list elements must have same names and lists must have same length")
    common.elements=intersect(names(x),names(y))

    res=lapply(common.elements, function(z){
      dat1=x[[z]]
      dat2=y[[z]]
      dat1=dat1[order(rownames(dat1)),,drop=F]
      dat2=dat2[order(rownames(dat2)),,drop=F]
      if (all(rownames(dat1)==rownames(dat2))) {
          qq=cbind(dat1,dat2)
          rownames(qq)=rownames(dat1)
          qq
      }
      else {
        id=intersect(rownames(dat1),rownames(dat2))
        dat1=dat1[match(id,rownames(dat1)),]
        dat2=dat2[match(id,rownames(dat2)),,drop=F]
        qq=cbind(dat1,dat2)
        rownames(qq)=rownames(dat1)
        qq
      }
    })
    names(res)=common.elements
    res

  } else stop("Comparison of a list and a data.frame under construction")
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/rankNA2.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

rankNA2 <-
function(x,ties.method="min",smallBetter=TRUE){
    r=rank((-1)^(!smallBetter)*x,ties.method=ties.method,na.last="keep")  #xtfrm maybe faster alternative
    if (any(is.na(x))){
        maxrank=ifelse(all(is.na(x)), yes=0, no=max(r,na.rm=TRUE))
        if (ties.method%in%c("min","random")) r[is.na(x)]<-maxrank+1
        if (ties.method=="average") r[is.na(x)]<-maxrank+mean(1:sum(is.na(x)))
    }
    r
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/significanceMap.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
significanceMap <- function(object,...) UseMethod("significanceMap")

#' @export
significanceMap.default <- function(object, ...) stop("not implemented for this class")

#' Creates significance maps
#'
#' Creates significance maps from a ranked assessment data set.
#'
#' @param object The ranked assessment data set.
#' @param alpha A numeric values specifying the significance level.
#' @param p.adjust.method A string specifying the adjustment method for multiple testing, see [stats::p.adjust()].
#' @param order
#' @param size.rank
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize ranking stability
#' @export
significanceMap.ranked.list=function(object,
                                     alpha=0.05,p.adjust.method="holm",
                                     order=FALSE,
                                     size.rank=.3*theme_get()$text$size,...){

  a=object$data%>%decision.challenge(na.treat=object$call[[1]][[1]]$na.treat,
                                     alpha=alpha,
                                     p.adjust.method=p.adjust.method)

  aa=lapply(a, as.relation.challenge.incidence)
  names(aa)=names(object$data)

  relensemble= do.call(relation_ensemble,args = aa)

  res=list()
  for (task in names(object$data)){
    res[[task]]=significanceMap.data.frame(object=object$matlist[[task]],
                                           relation_object=relensemble[[task]],
                                           order=order,
                                           size.rank=size.rank,...
                                           ) + ggtitle(task)

  }

  # Remove title for single-task data set
  if (length(res) == 1) {
    res[[1]]$labels$title <- NULL
    return(res[[1]])
  } else {
    names(res) = names(object$matlist)
    class(res) <- "ggList"
    return(res)
  }
 }


significanceMap.data.frame=function(object,
                                    relation_object,
                                    order=FALSE,
                                    size.rank=.3*theme_get()$text$size,...){

  object$algorithm=rownames(object)
  inc=relation_incidence(relation_object)

  if (order){
    scores=apply(inc,1,
                 function(x) sum(x==0)-1)
    scores2=apply(inc,2,
                  function(x) sum(x==1))[names(scores)]#+1-nrow(inc))
    scores=data.frame(algorithm=names(scores),
                      score=scores,
                      score2=scores2,
                      stringsAsFactors =F)
    scores=right_join(scores,
                      object,
                      by="algorithm")

    ordering= (scores[order(scores$score,
                            scores$score2,
                            scores$rank),"algorithm"])
    scores=scores[,1:3]
  } else ordering=  names(sort(t(object[,"rank",drop=F])["rank",]))

  inc=inc[ordering,]

  incidence.mat=melt(inc)
  colnames(incidence.mat)=c("algorithm","notsigPair",     "decision")
  incidence.mat$algorithm=as.character(incidence.mat$algorithm)
  incidence.mat$notsigPair=as.character(incidence.mat$notsigPair)
  incidence.mat=right_join(incidence.mat,
                           object,
                           by="algorithm")
  if (order) incidence.mat=right_join(incidence.mat,
                                      scores,
                                      by="algorithm")

  incidence.mat=incidence.mat%>%mutate(algorithm=factor(.data$algorithm,
                                                        levels=ordering),
                                       notsigPair=factor(.data$notsigPair,
                                                         levels=ordering))

  incidence.mat$decision=as.factor(incidence.mat$decision)

  p=ggplot(incidence.mat) +
    geom_raster(aes(algorithm,
                    notsigPair,
                    fill=decision),...)+
    geom_raster(aes(algorithm,algorithm),
                fill="white")+
    geom_abline(slope=1) +
    coord_cartesian(clip = 'off')+
    theme(aspect.ratio=1,
          axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
          plot.margin=unit(c(1,1,1,1), "lines"),
          legend.position="none")+
    ylab("Algorithm")+
    xlab("Algorithm")+
    scale_fill_manual(values=cividis(2,begin=0,end=1,alpha=.7))

  fixy=0
  th_get=theme_get()
  # grid on top
    lt=th_get$panel.grid$linetype
    if (is.null(lt)) lt=th_get$line$linetype
    gridSize=c(th_get$panel.grid.major$size,th_get$panel.grid$size,th_get$line$size)[1]


  #p=p+theme(panel.background = element_rect(fill = NA),panel.ontop=TRUE) #-> grid will be on top of diagonal
  #fix:
    f=ggplot_build(p)
    p= p + geom_vline(xintercept=f$layout$panel_params[[1]]$x$breaks,
                      linetype=lt,
                      color=th_get$panel.grid$colour,
                      size=gridSize)+
      geom_hline(yintercept=f$layout$panel_params[[1]]$y$breaks,
                 linetype=lt,
                 color=th_get$panel.grid$colour,
                 size=gridSize)+
      geom_abline(slope=1)+
      geom_text(aes(x=algorithm,y=fixy,label=rank),
                nudge_y=.5,
                vjust = 0,
                size=size.rank,
                fontface="plain",family="sans"
      )


  if (order) p=  p+
      geom_text(aes(x=algorithm,y=fixy,label=score),
                nudge_y=0,
                vjust = 0, size=size.rank,
                fontface="plain",family="sans") +
      annotate("text",
               x=0,y=fixy+.5,
               vjust = 0,
               size=size.rank,
               fontface="plain",
               family="sans",
               label="original")+
      annotate("text",x=0,y=fixy,
               vjust = 0,
               size=size.rank,
               fontface="plain",family="sans",label="new")

  return(p)

}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/winner.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

winner <- function(x,...) UseMethod("winner")
winner.default <- function(x, ...) stop("not implemented for this class")

winner.ranked.list <-winner.bootstrap.list <-function(x,...){
  lapply(x$matlist, function(z) z[which(z$rank==min(z$rank)),,drop=F])
}






# FILE: /mnt/data/challengeR_extracted/challengeR/R/violin.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
violin <- function(x,...) UseMethod("violin")

#' @export
violin.default <- function(x, ...) stop("not implemented for this class")

#' Creates a violin plot
#'
#' Creates a violin plot from a bootstrapped, ranked assessment data set.
#'
#' @param x The bootstrapped, ranked assessment data set.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize ranking stability
#' @export
violin.bootstrap.list=function(x,...){
  ken=melt(kendall.bootstrap.list(x))
  colnames(ken)[2]="Task"
  cat("\n\nSummary Kendall's tau:\n")
  ss=ken%>%group_by(Task)%>%
    summarise(mean=mean(value,na.rm=T),
              median=median(value,na.rm=T),
              q25=quantile(value,probs = .25,na.rm=T),
              q75=quantile(value,probs = .75,na.rm=T))%>%
    arrange(desc(median))

  print(knitr::kable(as.data.frame(ss)))

  # drop task if no kendall could be computed
    noResults <- sapply(split(ss,ss$Task),
                        function(x) all(is.na(x[,-1])))
    if (any(noResults)) {
      cat("\nNo Kendall's tau could be calculated for any bootstrap sample in task ",
              names(noResults)[noResults],
              " because of missing variability. Task dropped from figure.",fill=F)
      ken <- ken %>% filter(Task %in% names(noResults)[!noResults])

    }

  xAxisText <- element_blank()

  # Show task names as tick mark labels only for multi-task data set
  if (length(x$data) > 1) {
    xAxisText <- element_text(angle = 90, vjust = 0.5, hjust = 1)
  }

  ken%>%mutate(Task=factor(.data$Task,
                           levels=ss$Task))%>%
    ggplot(aes(Task,value))+
    geom_violin(alpha=.3,
                color=NA,
                na.rm=TRUE,
                fill="blue")+
    geom_boxplot(width=0.1,
                 na.rm=TRUE,
                 fill="white")+
    theme(axis.text.x = xAxisText,
          legend.position = "none")+
    ylab("Kendall's tau")+
    scale_y_continuous(limits=c(min(min(ken$value),0),
                                max(max(ken$value),1)))
}

kendall.bootstrap.list=function(x){
  ken=lapply(1:length(x$bootsrappedRanks),function(Task){
    id=match(rownames( x$bootsrappedRanks[[Task]]),
             rownames(x$matlist[[Task]]) )
    sapply(x$bootsrappedRanks[[Task]],
           function(bootSample) suppressWarnings(kendall(bootSample,
                                                         x$matlist[[Task]]$rank[id])))
  } )
  names(ken)=names((x$bootsrappedRanks))

  if (sum(is.na(x))>0){
   cat("Bootstrap samples without variability in rankings (all algorithms ranked 1) excluded.\n Frequency of such samples by task:\n",fill = T)
    sapply(ken,function(x) sum(is.na(x)))
  }


  return(ken)

}

density.bootstrap.list=function(x,...){
  ken=melt(kendall.bootstrap.list(x))
  colnames(ken)[2]="Task"

  cat("\n\nSummary Kendall's tau\n")
  ss=ken%>%group_by(Task)%>%
    summarise(mean=mean(value,na.rm=T),
              median=median(value,na.rm=T),
              q25=quantile(value,probs = .25,na.rm=T),
              q75=quantile(value,probs = .75,na.rm=T))%>%
    arrange(desc(median))

  print(as.data.frame(ss))

  ggplot(ken)+
    geom_density(aes(value,fill=Task),alpha=.3,color=NA)
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/methodsplot.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
methodsplot <- function(x,...) UseMethod("methodsplot")

#' @export
methodsplot.default <- function(x, ...) stop("not implemented for this class")

#' Creates line plots
#'
#' Create line plots that visualize the robustness of ranking across different ranking methods from a challenge object.
#'
#' @param x The challenge object.
#' @param na.treat Indicates how missing perfomance values are treated if sanity check is enabled. It can be 'na.rm', numeric value or function.
#'   For a numeric value or function, NAs will be replaced by the specified values. For 'na.rm', rows that contain missing values will be removed.
#' @param methods A list of ranking methods that should be incorporated.
#' @param ordering
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize ranking stability
#' @export
methodsplot.challenge=function(x,
                               na.treat=NULL,
                               methods=list(testBased=.%>%test() %>% rank(ties.method = "min"),
                                            meanThenRank=  .%>%  aggregate(  FUN="mean") %>% rank(ties.method = "min"),
                                            medianThenRank=.%>% aggregate(  FUN="median") %>% rank(ties.method = "min"),
                                            rankThenMean= .%>%rank(ties.method = "min") %>%  aggregate(  FUN="mean") %>%rank(ties.method = "min"),
                                            rankThenMedian=.%>%rank(ties.method = "min") %>%  aggregate(  FUN="median") %>%rank(ties.method = "min")
                                            ),
                               ordering, ...) {

  if (any(sapply(x,
                  function(task) any(is.na(task[,attr(x, "value")]))))) { # only if missings present, else do nothing
    if (is.null(na.treat)) {
      warning("Please specify na.treat in as.challenge()")
      return(NULL)
    } else {
      xx = melt(x,
                id.vars=c(attr(x,"value"),
                          attr(x,"algorithm") ,
                          attr(x,"case"),
                          attr(x,"annotator"),
                          attr(x,"by")
      ))

      x=as.challenge(xx,
                     value=attr(x,"value"),
                     algorithm=attr(x,"algorithm") ,
                     case=attr(x,"case"),
                     by=attr(x,"by"),
                     annotator = attr(x,"annotator"),
                     smallBetter = attr(x,"smallBetter"),
                     na.treat=na.treat)
    }
  }

  a=lapply(methods,function(fun) fun(x))
  dat=melt(a,measure.vars="rank")
  colnames(dat)[4:5]=c("task","rankingMethod")

  if (missing(ordering)){
    lev=sort(unique(dat$algorithm))
    lab=lev
  } else {
    lev=ordering
    lab=lev
  }

  dat=dat%>%
    dplyr::rename(rank=.data$value)%>%
    mutate(rank=factor(.data$rank))%>%
    mutate(task=factor(.data$task))%>%
    mutate(algorithm=factor(.data$algorithm, levels=lev,labels = lab))

  linePlot <- ggplot(data = dat) +
    aes(x = rankingMethod, y = rank, color=algorithm, group=algorithm ) +
    geom_line(size=1)+
    xlab("Ranking method")  +
    ylab("Rank")+
    theme(
      strip.placement = "outside",
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
    )

  # Create multi-panel plot with task names as titles for multi-task data set
  if (length(x) > 1) {
    linePlot <- linePlot + facet_wrap(~ task)
   }

  return(linePlot)
}

# methodsplot.ranked.list does not exist, use methodpsplot.challenge instead since consonsus ranking needed for ordering (or alphabetical ordering instead)

#similar plot to methods plot, instead of across ranking methods across tasks
lineplot <- function(x,...) UseMethod("lineplot")
lineplot.default <- function(x, ...) stop("not implemented for this class")

lineplot.challenge=function(x,
                            ordering,...){
  if (inherits(x,"list"))  {
    dat=melt(x,measure.vars="rank")
    colnames(dat)[4]=c("task")

    if (missing(ordering)){
      lev=sort(unique(dat$algorithm))
      lab=lev
    } else {
      lev=ordering
      lab=paste(1:length(ordering),ordering)
    }

    dat=dat%>%
      dplyr::rename(rank=.data$value)%>%
      mutate(rank=factor(.data$rank))%>%
      mutate(task=factor(.data$task))%>%
      mutate(algorithm=factor(.data$algorithm, levels=lev,labels = lab))

    ggplot(data = dat) +
      aes(x = task, y = rank, color=algorithm, group=algorithm ) +
      geom_line(size=1)+
      theme(
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1) )

  } else stop("Only applicable to multiple tasks")
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/Rank.aggregated.list.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

rank.aggregated.list <-function(object,
                                ties.method="min",
                                smallBetter,
                                ...){

  call=match.call(expand.dots = F)
  if (missing(smallBetter)){
    if (!is.null(attr(object$data,"smallBetter"))) smallBetter=attr(object$data,"smallBetter")
    else stop("smallBetter has to be provided either in as.challenge() or rank()")

    if (object$isSignificance) smallBetter=FALSE  # smallBetter already taken care of by one-sided test nature of signficance
  }

  call=call("rank.aggregated.list",
            object=call$object,
            ties.method=ties.method,
            smallBetter=smallBetter)

  matlist=object$matlist

  matlist=lapply(matlist,
                 function(y){
                   if (nrow(y)>0) r=rankNA2(y[,ncol(y)],
                                            ties.method=ties.method,
                                            smallBetter=smallBetter)
                   else r=NULL
                   res=cbind(y,rank=r)
                   res
                   })

  res=list(matlist=matlist,
           data=object$data,
           call=list(object$call,call),
           FUN =  . %>% (object$FUN) %>%  (call),
           FUN.list=c(object$FUN.list,
                      "rank")
      )
  class(res)=c("ranked.list",class(res))

  res
}

rank.aggregatedRanks.list <-function(object,
                                     ties.method="min",
                                     ...){

  call=match.call(expand.dots = F)
  call=call("rank.aggregatedRanks.list",
            object=call$object,
            ties.method=ties.method)
  matlist=object$matlist

  matlist=lapply(matlist, function(y){
        if (nrow(y)>0) r=rankNA2(y[,ncol(y)],
                                 ties.method=ties.method,
                                 smallBetter=TRUE)
        else r=NULL
        res=cbind(y,rank=r)
        res
  })

  res=list(matlist=matlist,
           data=object$data,
           call=list(object$call,call),
           FUN =  . %>% (object$FUN) %>%  (call),
           FUN.list=c(object$FUN.list,
                      "rank")
           )
  class(res)=c("ranked.list",class(res))
  res

  res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/consensus.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
consensus <- function(object,...) UseMethod("consensus")

#' @export
consensus.default <- function(object, ...) stop("not implemented for this class")

#' Computes a consensus ranking
#'
#' Computes a consensus ranking (rank aggregation) across tasks.
#'
#' @param object The ranked asssessment data set.
#' @param method A string specifying the method to derive the consensus ranking, see [relations::consensus()] for the methods. Consensus ranking according to mean ranks across tasks if method="euclidean" where in case of ties (equal ranks for multiple algorithms) the average rank is used, i.e. ties.method="average".
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#' @export
consensus.ranked.list=function(object,
                               method,
                               ...){
  relensemble= relation_ensemble(list = as.relation(object))
  cons=relation_consensus(relensemble,
                          method = method,...) # consensus ranking according to mean ranks across tasks if method="euclidean".
  # See ?relation_consensus for different methods to derive consensus ranking
  res=sort(relation_scores(cons,
                           decreasing=FALSE)) # note that there may be ties (i.e. some algorithms have identical mean rank)
  attr(res,"method")=method
  res
  }


# FILE: /mnt/data/challengeR_extracted/challengeR/R/podium.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
podium <- function(object,...) UseMethod("podium")

#' @export
podium.default <- function(object, ...) stop("not implemented for this class")

#' Creates podium plots
#'
#' Creates podium plots from one or more ranked assessment data sets.
#'
#' @param object The ranked asssessment data set.
#' @param xlab A string specifying the x-axis label.
#' @param ylab A string specifying the y-axis label.
#' @param lines.show
#' @param lines.alpha
#' @param lines.lwd
#' @param lines.lty
#' @param lines.col
#' @param col
#' @param dots.pch
#' @param dots.cex
#' @param places.lty
#' @param places.col
#' @param legendfn
#' @param layout.heights
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize assessment data
#' @export
podium.ranked.list=function(object,
                            xlab = "Podium",
                            ylab = "Performance",
                            lines.show = TRUE,
                            lines.alpha = 0.2,
                            lines.lwd = 1,
                            lines.lty=1,
                            lines.col = col,
                            col,
                            dots.pch = 19,
                            dots.cex = 1,
                            places.lty = 2,
                            places.col = 1,
                            legendfn = function(algs, cols) {
                              legend("topright", algs, lwd = 1, col = cols, bg = "white")
                            },
                            layout.heights=c(1,0.4),
                            ...){
    x=object$data

    podiumPlots <- length(names(x))

    for (subt in names(x)) {
      ordering=t(object$matlist[[subt]][,"rank",drop=F])["rank",]
      if (missing(col)) col=default_colors(length(ordering),
                                           algorithms = names(ordering))

      dd=as.challenge(x[[subt]],
                      value=attr(x,"value"),
                      algorithm=attr(x,"algorithm"),
                      case=attr(x,"case"),
                      by=attr(x, "by"),
                      annotator = attr(x,"annotator"),
                      smallBetter = attr(x,"smallBetter"),
                      na.treat=object$call[[1]][[1]]$na.treat)

      podiumPlot <- podium(dd,
             ordering=ordering,
             xlab = xlab, ylab = ylab,
             lines.show = lines.show,
             lines.alpha = lines.alpha,
             lines.lwd = lines.lwd,
             lines.lty = lines.lty,
             col=col,
             lines.col = lines.col,
             dots.pch = dots.pch,
             dots.cex = dots.cex,
             places.lty = places.lty,
             places.col = places.col,
             legendfn = legendfn,
             layout.heights=layout.heights,
             ...)

      if (length(names(x)) > 1) {
        title(subt,outer=T,line=-3)
      }

      append(podiumPlots, podiumPlot)
    }
}

#' Creates a podium plot
#'
#' Creates a podium plot from a challenge object.
#'
#' @param object The challenge object.
#' @param ordering
#' @param xlab A string specifying the x-axis label.
#' @param ylab A string specifying the y-axis label.
#' @param lines.show
#' @param lines.alpha
#' @param lines.lwd
#' @param lines.lty
#' @param lines.col
#' @param col
#' @param dots.pch
#' @param dots.cex
#' @param places.lty
#' @param places.col
#' @param legendfn
#' @param layout.heights
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize assessment data
#' @export
podium.challenge=function(object,
                          ordering,
                          xlab = NULL, ylab = NULL,
                          lines.show = FALSE, lines.alpha = 0.2,
                          lines.lwd = 1,
                          lines.lty = 1,
                          col,lines.col = col,
                          dots.pch = 19, dots.cex = 1,
                          places.lty = 2, places.col = 1,
                          legendfn = function(algs, cols) {
                            legend("topleft", algs, lwd = 1, col = cols, bg = "white")
                          },
                          layout.heights=c(1,0.4),
                          ...) {

  ranking=object%>%rank( ties.method = "random" )

  task <- ranking$matlist[[1]]

  dat=as.data.frame(table(task[[attr(object, "algorithm")]],
                          task$rank,
                          dnn=c("algorithm","rank")),
                    responseName = "Count")

  form=as.formula(paste(attr(object,"case"), attr(object,"algorithm"), sep="~"))
  ranks=acast(task, form, value.var="rank")
  values=acast(task, form, value.var=attr(object, "value"))
  nranks=acast(dat, algorithm~rank, value.var="Count")

  nalgs <- ncol(ranks)
  algs <- colnames(ranks)

  barorder <- order(ordering)
  orderedAlgorithms= names(ordering)[barorder]

  ylim=range(task[[attr(object,"value")]], na.rm = TRUE)

  dotplotborders <- (0:nalgs) * nalgs
  dotplaces <- (1:nalgs) - 0.5
  names(dotplaces) <- orderedAlgorithms

  linecols <- sapply(lines.col, function(c) {
    r <- col2rgb(c)
    rgb(r[1], r[2], r[3],
        alpha = round(255 * lines.alpha),
        maxColorValue = 255)
  })

  opar <- par(no.readonly = TRUE)
  layout(matrix(c(1, 2), nrow = 2, byrow = TRUE),
         heights =layout.heights)

  mar <- par("mar")
  par(mar = c(0, mar[2], mar[3], mar[4]))

  plot(dotplotborders, rep(ylim[2], nalgs + 1),
       type = "n",
       ylim = ylim, ylab = ylab, xlab = "",
       axes = F)
  axis(1, at = dotplotborders,
       labels = NA, lwd = par("lwd"))
  axis(2, lwd = par("lwd"))
  box()
  abline(v = dotplotborders, lty = places.lty, col = places.col)
  linesegments <- function(x, y, ...) {
    n <- length(x)
    segments(x[-n], y[-n], x[-1], y[-1], ...)
  }
  drawthe <- function(fn, col, ...) {
    for (i in 1:nrow(values)) {
      r <- ranks[i, ]
      o <- order(r)
      performances <- (values[i, ])[o]
      places <- (dotplaces[names(r)] + ((r - 1) * nalgs))[o]
      fn(places, performances, 
         col = col[names(r)[o]], 
         pch = switch((length(dots.pch)!=1)+1,
                      dots.pch,
                      dots.pch[names(r)[o]]), 
         lty = switch((length(lines.lty)!=1)+1,
                      lines.lty,
                      lines.lty[names(r)[o]]),
         ...)
    }
  }
  if (lines.show) drawthe(linesegments, linecols, lwd = lines.lwd)

  drawthe(points, col,  cex = dots.cex)


  par(mar = c(mar[1], mar[2], 0, mar[4]))
  barplot(nranks[barorder,],
          beside = TRUE,
          width = 1,
          axes = F,
          space = c(0, 0),
          border = NA,
          ylim = c(0, nrow(ranks)),
          names.arg = paste(1:nalgs, ".", sep = ""),
          col = col[orderedAlgorithms],
          xlab = xlab)
  axis(1, at = c(0, dotplotborders),
       labels = NA, lwd = par("lwd"))
  box()
  par(opar)
  legendfn(orderedAlgorithms,
           col[orderedAlgorithms])
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/rankingHeatmap.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
rankingHeatmap <- function(x,...) UseMethod("rankingHeatmap")

#' @export
rankingHeatmap.default <- function(x, ...) stop("not implemented for this class")

#' Creates ranking heatmaps
#'
#' Creates ranking heatmaps from one or more ranked assessment data sets.
#'
#' @param x The ranked asssessment data set.
#' @param ties.method A string specifying how ties are treated, see [base::rank()].
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize assessment data
#' @export
rankingHeatmap.ranked.list=function (x,ties.method="min",...) {

  xx=x$data

  a=lapply(names(x$matlist),function(subt){
    ordering=rownames(x$matlist[[subt]])[order(x$matlist[[subt]]$rank)]

    dd=as.challenge(xx[[subt]],
                    value=attr(xx,"value"),
                    algorithm=attr(xx,"algorithm") ,
                    case=attr(xx,"case"),
                    by=attr(xx, "by"),
                    annotator = attr(xx,"annotator"),
                    smallBetter = attr(xx,"smallBetter"),
                    na.treat=x$call[[1]][[1]]$na.treat)

    rankingHeatmap(dd,
                   ordering=ordering,
                   ties.method=ties.method,...) + ggtitle(subt)
  })

  # Remove title for single-task data set
  if (length(a) == 1) {
    a[[1]]$labels$title <- NULL
    return(a[[1]])
  } else {
    names(a) = names(x$matlist)
    class(a) <- "ggList"
    return(a)
  }

}

#' Creates a ranking heatmap
#'
#' Creates a ranking heatmap from a challenge object.
#'
#' @param x The challenge object.
#' @param ordering
#' @param ties.method A string specifying how ties are treated, see [base::rank()].
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize assessment data
#' @export
rankingHeatmap.challenge=function(x,
                                  ordering,
                                  ties.method="min",...) {
  ranking=x%>%rank( ties.method = ties.method )

  task <- ranking$matlist[[1]]

  dat=as.data.frame(table(task[[attr(x,"algorithm")]],
                          task$rank,
                          dnn=c("algorithm","rank")),
                    responseName = "Count")
  dat$algorithm=factor(dat$algorithm, levels=ordering)
  ncases=length(unique(task[[attr(x,"case")]]))
  ggplot(dat)+
    geom_raster(aes(algorithm, rank, fill= Count))+
    geom_hline(yintercept = seq(1.5,
                                max(max(task$rank)-.5,
                                    1.5),
                                by=1),
               color=grey(.8),size=.3)+
    geom_vline(xintercept = seq(1.5,
                                length(unique(dat$algorithm))-.5,
                                by=1),
               color=grey(.8),size=.3)+
    scale_fill_viridis_c(direction = -1,
                         limits=c(0,ncases)
    )+
    theme(axis.text.x = element_text(angle = 90),
          aspect.ratio=1)+
    xlab("Algorithm")+
    ylab("Rank")
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/graph.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

network <- function(x,...) UseMethod("network")
network.default <- function(x, ...) stop("not implemented for this class")

network.ranked.list=function(x,
                             method = "symdiff",
                             edge.col,
                             edge.lwd,
                             rate=1.05,
                             cols,
                              ...) {
  if (length(x$data) < 3) {
    stop("The cluster analysis is only sensible for more than two tasks.")
  }

  # use ranking list
  relensemble=as.relation.ranked.list(x)

  # # use relations
  #   a=challenge_multi%>%decision.challenge(p.adjust.method="none")
  #   aa=lapply(a,as.relation.challenge.incidence)
  #   names(aa)=names(challenge_multi)
  #   relensemble= do.call(relation_ensemble,args = aa)
  d <- relation_dissimilarity(relensemble, method = method)

  #coloring
  # # use relations
  # rm <-my.bsranking(relensemble) #for coloring
  # uw <- apply(rm, 2,
  #             function(x) {
  #               w <- which(x == 1)
  #               ifelse(length(w) == 1,
  #                      names(w), "none")
  #             })
  # use ranking list
  uw=lapply(x$matlist,function(task.i) rownames(task.i)[which(task.i$rank==1)])
  uw=sapply(uw, function(task.i) ifelse(length(task.i)==1,yes = task.i,no="none"))

  network.dist(d,
                 edge.col = edge.col,# grDevices::grey.colors(nn), #terrain_hcl(nn, c=c(65,0), l=c(45,90), power=c(1/2,1.5)),
                 edge.lwd =edge.lwd,#4*rev(1.2^seq_len(length(unique(d)))/(1.2^length((unique(d))))),# seq(1, .001, length.out=nn),
                 rate=rate,
                 node.fill = cols[uw],...
  )
}



network.dist=
  function (x, rate=1.05, #ndists.show = length(sort(unique(x))),
            edge.col = gray(0.7),
            edge.lwd = 1,
            node.fill = NULL,
            ...) {
    nn=length(unique(c(x))) # ==max(rm) number of different distance levels
    if (is.function(edge.col)) edge.col=edge.col(nn)
    data <- as.matrix(x)
    nodes <- colnames(data)
    nnodes <- length(nodes)
    dists <- sort(unique(x))
    ndists <- length(dists)
    dshow <- dists#[seq_len(ndists.show)]
    ndshow <- length(dshow)
    edge.col <- rep(edge.col, ndshow)
    edge.lwd <- rep(edge.lwd, ndshow)
    edge.len <- ceiling((rate)^dists)# exponential distance
    #   edge.len <- ceiling((1.2)^(seq_len(ndists) - 1)) #verwende ordnung
    #   edge.len <- ceiling((1.05)^(dists-min(dists)+1))# verwende distance mit min==1
    edge.weight <- rev(dists) #rev(seq_len(ndists))
    edge.lty <- c(rep("solid", ndshow),
                  rep("blank", length(dists) - ndshow))
    graph <- new("graphNEL",
                 nodes = nodes,
                 edgemode = "undirected")
    edgeAttrs <- list()
    nodeAttrs <- list()
    for (i in 1:(nnodes - 1)) {
      for (j in (i + 1):nnodes) {
        s <- data[i, j]
        # if (s %in% dshow) {
        t <- which(s == dists)
        graph <- graph::addEdge(nodes[i], nodes[j], graph, 1) #edge.weight[t])
        n <- paste(nodes[i], nodes[j], sep = "~")
        edgeAttrs$len[n] <- edge.len[t] # laenge exponentiell
        #        edgeAttrs$len[n] <- s # laenge prop zu distance
        edgeAttrs$color[n] <- "black"#edge.col[t]
        edgeAttrs$lwd[n] <- edge.lwd[t]
        edgeAttrs$lty[n] <- 1#edge.lty[t]
        #   }
      }
    }
    if (!is.null(node.fill))
      nodeAttrs$fillcolor[nodes] <- node.fill

    out= list(graph=graph,
              nodeAttrs = nodeAttrs,
              edgeAttrs = edgeAttrs,
              tasknames=nodes,
              leg.col=node.fill[unique(names(node.fill))]
    )
    class(out)="network"
    out
  }


plot.network=function(x,
                      layoutType = "neato",
                      fixedsize=TRUE,
                      fontsize,
                      width,
                      height,
                      shape="ellipse",
                      cex=.8,
                      ...
){
  graph=x$graph
  nodeAttrs=x$nodeAttrs
  edgeAttrs=x$edgeAttrs
  leg.col=x$leg.col

  layoutType = layoutType
  attrs <- Rgraphviz::getDefaultAttrs(layoutType = layoutType)
  attrs$node$fixedsize <- fixedsize
  attrs$node$shape=shape
  if (missing(fontsize)) {
    attrs$node$fontsize <- max(sapply(x$tasknames,nchar))-1
  } else attrs$node$fontsize=fontsize
  if (missing(width)){
    attrs$node$width <- max(sapply(x$tasknames,nchar))
  } else attrs$node$width=width
  if (missing(height)) {
    attrs$node$height <- max(sapply(x$tasknames,nchar))/2
  } else attrs$node$height=height

  ag <- Rgraphviz::agopen(graph,
                          "",
                          layoutType = layoutType,
                          attrs = attrs,
                          nodeAttrs = nodeAttrs,
                          edgeAttrs = edgeAttrs)

    plot.new()
    l=legend("topright",
             names(leg.col),
             lwd = 1,
             cex=cex,
             bg =NA,
             plot=F)# bg="white")
    w <- grconvertX(l$rect$w, to='inches')

    Rgraphviz::plot(ag,mai=c(0,0,0,w),...)
    legend(par('usr')[2], par('usr')[4],
           xpd=NA,
           names(leg.col),
           lwd = 1,
           col = leg.col,
           bg =NA,
           cex=cex)# bg="white")

}





#library(R.utils)
#reassignInPackage("beplot0.matrix","benchmark",my.beplot0.matrix)
#reassignInPackage("beplot0.AlgorithmPerformance","benchmark",my.beplot0.AlgorithmPerformance)


# FILE: /mnt/data/challengeR_extracted/challengeR/R/Aggregate.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

Aggregate <- function(object,...) UseMethod("Aggregate")
Aggregate.default <- function(object, ...) aggregate(object,...)  #stats::aggregate

Aggregate.list <-function(object,
                          x,
                          algorithm,
                          FUN = mean,
                          na.treat = "na.rm",
                          parallel = FALSE,
                          progress = "none",
                          case,
                          alpha = 0.05,
                          p.adjust.method = "none",
                          alternative = "one.sided",
                          test.fun = function(x, y) wilcox.test(x,
                                                                y,
                                                                alternative = alternative,
                                                                exact = FALSE,
                                                                paired = TRUE)$p.value,
                          smallBetter = FALSE,   # only needed for significance
                          ...            ) {
  call=match.call(expand.dots = T)
  if (is.character(FUN) && FUN=="significance"){
    if(missing(case)|  missing(smallBetter)|  missing(alpha)) stop("If FUN='significance' arguments case, smallBetter and alpha need to be given")
    matlist=llply(1:length(object),
                  function(id){
                    piece=object[[id]]
                    if (length(unique(piece[[algorithm]]))<=1){
                      warning("Only one algorithm available in task '", names(object)[id], "'.")
                      return(data.frame("prop_significance"=rep(NA,length(unique(piece[[algorithm]]))),
                                        row.names = unique(piece[[algorithm]])))
                    }
                    if (is.numeric(na.treat)) piece[,x][is.na(piece[,x])]=na.treat
                    else if (is.function(na.treat)) piece[,x][is.na(piece[,x])]=na.treat(piece[,x][is.na(piece[,x])])
                    else if (na.treat=="na.rm") piece=piece[!is.na(piece[,x]),]
                    else stop("Argument 'na.treat' is invalid. It can be 'na.rm', numeric value or function.")

                    xmean <- significance(piece,
                                          x,
                                          algorithm,
                                          case,
                                          alpha,
                                          p.adjust.method=p.adjust.method,
                                          smallBetter,
                                          alternative=alternative,
                                          ...)
                    class(xmean)=c("aggregated",
                                   class(xmean))
                    xmean
                    },
                  .parallel=parallel,
                  .progress=progress
    )
    isSignificance=TRUE

  } else {
    if (is.function(FUN)) FUNname <-gsub('\")',"",gsub('UseMethod(\"',"",deparse(functionBody(FUN)),fixed = T),fixed=T)
    else if (is.character(FUN)) FUNname=FUN

    if (is.character(FUN)) FUN=try(eval(parse(text=FUN)),
                                   silent = T)
    if (!is.function(FUN)) stop("FUN has to be a function (possibly as character) or 'significance'")

    matlist=llply(object,
                  function(piece){
                    if (is.numeric(na.treat)) piece[,x][is.na(piece[,x])]=na.treat
                    else if (is.function(na.treat)) piece[,x][is.na(piece[,x])]=na.treat(piece[,x][is.na(piece[,x])])
                    else if (na.treat=="na.rm") piece=piece[!is.na(piece[,x]),]
                    else stop("Argument 'na.treat' is invalid. It can be 'na.rm', numeric value or function.")

                    xmean <- aggregate(piece[,x],
                                       by=list(piece[,algorithm]),
                                       FUN=function(z) do.call(FUN,args=list(x=z)))
                    names(xmean)=c(algorithm,
                                   paste0(x,"_",FUNname))
                    rownames(xmean)=xmean[,1]
                    xmean=xmean[,-1,drop=F]
                    xmean
                  },
                  .parallel=parallel,
                  .progress=progress
                  )
    isSignificance=FALSE
  }
  names(matlist)=names(object)
  res=list(FUN = . %>% (call),
           FUN.list=list(FUN),
           call=list(call),
           data=object,
           matlist=matlist,
           isSignificance=isSignificance
           )

  class(res)=c("aggregated.list",class(res))
  res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/firstlib.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

.onAttach <- function (lib, pkg) {
  ver <- read.dcf(file.path(lib,pkg,"DESCRIPTION"),"Version")
  ver <- as.character(ver)
  packageStartupMessage("\nchallengeR ",
                        ver,
                        " loaded. \n",
                        #                       "Note: Layouting in case of many algorithms or tasks is not yet optimized. Please be patient, we are steadily working on improving the package",
                        "\nPlease cite as:\n   Wiesenfarth, M., Reinke, A., Landman, B.A., Eisenmann, M., Aguilera Saiz, L., Cardoso, M.J., Maier-Hein, L. and Kopp-Schneider, A. Methods and open-source toolkit for analyzing and visualizing challenge results. Sci Rep 11, 2369 (2021). https://doi.org/10.1038/s41598-021-82017-6\n",
                        domain = NULL,
                        appendLF = TRUE)
}

.onLoad <- function(...) {
}

.onUnload <- function (libpath) {
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/challengeR.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' Constructs a challenge object
#'
#' Constructs an S3 object to represent the configuration of an assessment data set originating from a benchmarking competition (so-called "challenge").
#'
#' @section Assessment data set:
#' The toolkit provides visualization approaches for both challenges designed around a single task (single-task challenges) and for challenges comprising multiple tasks (multi-task challenges).
#' For a single-task challenge, the assessment data set (argument \code{object}) requires the following columns:
#' \itemize{
#'   \item test case identifier (string or numeric)
#'   \item algorithm identifier (string or numeric)
#'   \item performance value (numeric)
#' }
#'
#' For a multi-task challenge, the assessment data set (argument \code{object}) requires the following columns:
#' \itemize{
#'   \item task identifier (string or numeric)
#'   \item test case identifier (string or numeric)
#'   \item algorithm identifier (string or numeric)
#'   \item performance value (numeric)
#' }
#'
#' @section Sanity check:
#' It is highly recommended that the sanity check is not disabled when the data set is provided initially.
#' It checks that:
#' \itemize{
#'   \item performance values are numeric (if not, raises error)
#'   \item algorithm performances are observed for all cases (if not, adds them as NA and emits a message)
#'   \item cases appear only once for the same algorithm (if not, raises error)
#' }
#' If the argument \code{na.treat} for treatment of NA is specified, NAs will be handled respectively.
#'
#' It might be reasonable to disable the sanity check for further computations (e.g., for performance reasons
#' during bootstrapping (\code{\link{bootstrap.ranked.list}}) where cases are actually allowed to appear more than once for the same algorithm).
#'
#' @param object A data frame containing the assessment data.
#' @param case A string specifying the name of the column that contains the case identifiers.
#' @param algorithm A string specifying the name of the column that contains the algorithm identifiers.
#' @param value A string specifying the name of the column that contains the performance values.
#' @param by A string specifying the name of the column that contains the task identifiers. Required for multi-task data set.
#' @param taskName A string specifying the task name for single-task data set that does not contain a task column.
#'   This argument is optional for a single-task data set and is ignored for a multi-task data set.
#' @param annotator If multiple annotators annotated the test cases, a string specifying the name of the column that contains the annotator identifiers. Only applies to rang-then-aggregate. Use with caution: Currently not tested.
#' @param smallBetter A boolean specifying whether small performance values indicate better algorithm performance.
#' @param na.treat Indicates how missing perfomance values are treated if sanity check is enabled. It can be 'na.rm', numeric value or function.
#'   For a numeric value or function, NAs will be replaced by the specified values. For 'na.rm', rows that contain missing values will be removed.
#' @param check A boolean to indicate to perform a sanity check of the specified data set and arguments if set to \code{TRUE}.
#'
#' @return An S3 object to represent the configuration of an assessment data set.
#'
#' @examples
#' # single-task data set
#'
#' # multi-task data set
#'
#' @export
as.challenge=function(object,
                      case,
                      algorithm,
                      value,
                      by=NULL,
                      taskName=NULL,
                      annotator=NULL,
                      smallBetter=FALSE,
                      na.treat=NULL, # optional
                      check=TRUE) {

  object=as.data.frame(object[,c(value, algorithm, case, by, annotator)])
  object[[algorithm]] <- as.factor(object[[algorithm]])
  # sanity checks
  if (check) {
 
    if (!is.null(by) && !is.null(taskName)) {
      warning("Argument 'taskName' is ignored for multi-task data set.")
    }

    # Add task column for data set without task column by using the specified task name.
    if (is.null(by) && !is.null(taskName)) {
      taskName <- trimws(taskName)

      if (taskName == "") {
        stop("Argument 'taskName' is empty.")
      }

      object <- cbind(task=taskName, object)
      by = "task"
    }

    # Add task column for data set without task column by using a dummy task name.
    if (is.null(by) && is.null(taskName)) {
      object <- cbind(task="dummyTask", object)
      by = "task"
    }

    object=splitby(object,by=by)
    object=lapply(object,droplevels)
    missingData = n.missing = list()
    for (task in names(object)) {
      if (!all(is.numeric(object[[task]][[value]]))) stop("Performance values must be numeric.")

      n.missing[[task]] <- sum(is.na(object[[task]][[value]])) # already missing before na.treat; for report
      if (n.missing[[task]]>0) message("Note: ", n.missing, " missing cases have been found in the data set.")
      # check for missing cases
        missingData[[task]]=object[[task]] %>%
          expand(!!as.symbol(algorithm),
                 !!as.symbol(case))%>%
          anti_join(object[[task]],
                    by=c( algorithm,case))
        if (nrow(missingData[[task]])>0) {
             if (length(object) == 1 ) { # single task
            message("Performance of not all algorithms has been observed for all cases.\nTherefore, missings have been inserted in the following cases:")
          } else { # multi task
            message("Performance of not all algorithms has been observed for all cases in task '",
                    task,
                    "'.\nTherefore, missings have been inserted in the following cases:")

          }
          print(as.data.frame(missingData[[task]]))
          object[[task]]=as.data.frame(object[[task]] %>%
                                         complete(!!as.symbol(by),
                                                  !!as.symbol(algorithm),
                                                  !!as.symbol(case)))
        }
      # check duplicate cases
         all1=apply(table(object[[task]][[algorithm]],
                           object[[task]][[case]]),
                     2,
                     function(x) all(x==1))
          if (!all(all1)) {
            n.duplicated <- sum(all1!=1)

            if (length(object) == 1 ) { # single task
              if (n.duplicated/length(all1) >= 1/5) { # at least a quarter of the cases is duplicated
                stop ("The following case(s) appear(s) more than once for the same algorithm. Please revise. ",
                      "Or are you considering a multi-task challenge and forgot to specify argument 'by'?\n",
                      "Case(s): ",
                      paste(names(which(all1!=1)), collapse=", ")
                      )
              } else {
                stop ("The following case(s) appear(s) more than once for the same algorithm. Please revise.\n",
                      "Case(s): ",
                      paste(names(which(all1!=1)), collapse=", ")
                      )
              }
            } else { # multi task
              stop ("The following case(s) appear(s) more than once for the same algorithm in task '",
                    task, "'. Please revise.\n",
                     "Case(s): ",
                    paste(names(which(all1!=1)), collapse=", ")
                    )

            }
          }

      if (!is.null(na.treat)) {
        if (is.numeric(na.treat)) object[[task]][,value][is.na(object[[task]][,value])]=na.treat
        else if (is.function(na.treat)) object[[task]][,value][is.na(object[[task]][,value])]=na.treat(object[[task]][,value][is.na(object[[task]][,value])])
        else if (is.character(na.treat) && na.treat=="na.rm") object[[task]]=object[[task]][!is.na(object[[task]][,value]),]
      }
    }
  }

  if (check==TRUE && (any(sapply(missingData, function(x) nrow(x))>0) | any(n.missing>0)))  {
    ##
    ## The message below was disabled because it can cause misinformation even we supply na.treat to as.challenge object
    ##
    # if (is.null(na.treat)) message("For aggregate-then-rank, na.treat will have to be specified. ",
    #                                "For rank-then-aggregate, missings will implicitly lead to the algorithm ranked last for the missing test case.",
    #                                "na.treat obligatory if report is intended to be compiled."
    #                            )
    if (is.numeric(na.treat)) message("All missings have been replaced by the value ", na.treat,".\n")
    else if (is.character(na.treat) && na.treat=="na.rm") message("All missings have been removed.")
    else if (is.function(na.treat)) {
      message("Missings have been replaced using function ")
      print(na.treat)
    }
  }

  if (check==TRUE){
    attr(object,"n.missing")=n.missing
    attr(object,"missingData")=missingData
  }
  attr(object,"na.treat")=na.treat

  attr(object,"algorithm")=algorithm
  attr(object,"value")=value
  attr(object,"case")=case
  attr(object,"annotator")=annotator
  attr(object,"by")=by
  attr(object,"smallBetter")=smallBetter
  attr(object,"check")=check
  class(object)=c("challenge", class(object))
  object
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/Bootstrap.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

bootstrap <- function(object,...) UseMethod("bootstrap")
bootstrap.default <- function(object, ...) stop("not implemented for this class")


#' Performs bootstrapping
#'
#' Performs bootstrapping on a ranked assessment data set and applies the ranking method to each bootstrap sample. One bootstrap sample of
#' a task with \code{n} cases consists of \code{n} cases randomly drawn with replacement from this task.
#' A total of \code{nboot} of these bootstrap samples are drawn.
#'
#' To ensure reproducibility, please use the doRNG package on Windows or RNG kind = "L'Ecuyer-CMRG" in set.seed(), e.g. set.seed(1, kind = "L'Ecuyer-CMRG").
#'
#' @param object The ranked assessment data set.
#' @param nboot The number of bootstrap samples.
#' @param parallel A boolean specifying whether parallel processing should be enabled.
#' @param progress A string specifying the type of progress indication.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return An S3 object of class "bootstrap.list" to represent a bootstrapped, ranked assessment data set.
#'
#' @examples
#'
#' \dontrun{
#'  # perform bootstrapping with 1000 bootstrap samples using one CPU
#'  set.seed(123, kind="L'Ecuyer-CMRG")
#'  ranking_bootstrapped <- bootstrap(ranking, nboot = 1000)
#' }
#'
#' \dontrun{
#'  # perform bootstrapping using multiple CPUs (here: 8 CPUs)
#'  library(doParallel)
#'  library(doRNG)
#'  registerDoParallel(cores = 8)
#'  registerDoRNG(123)
#'  ranking_bootstrapped <- bootstrap(ranking, nboot = 1000, parallel = TRUE, progress = "none")
#'  stopImplicitCluster()
#' }
#'
#' @export
bootstrap.ranked.list=function(object,
                               nboot,
                               parallel=FALSE,
                               progress="text",
                               ...){
  algorithm=attr(object$data,"algorithm")
  by=attr(object$data,"case")

  # exclude if only 1 test case or only 1 algorithm
  tidy.data.id=sapply(object$data,
                      function(data.subset) {
                        ifelse((length(unique(data.subset[[by]]))==1 |  length(unique(data.subset[[algorithm]]))<=1 ),
                               yes=FALSE,
                               no=TRUE)
                        })
  
  if (sum(tidy.data.id)==0) {
    if (length(object$matlist)>1) stop("All tasks only contained 1 test case. Bootstrapping with 1 test case not sensible.")
    else stop("Only 1 test case included. Bootstrapping with 1 test case not sensible.")
  }
  if (sum(tidy.data.id)<length(object$matlist)) message("Task(s) ", 
                                                        paste(names(tidy.data.id)[!tidy.data.id], collapse = ", "),
                                                        " with only 1 test case excluded from bootstrapping.")   
  
  tidy.data=object$data[tidy.data.id]
  tidy.matlist=object$matlist[tidy.data.id]

  res= llply(1:nboot,
             function(it){
               # draw 1 sample for each task
               bootDatalist = lapply(tidy.data, function(data.subset) {
                 index = unique(data.subset[[by]])

                 # bootIndex=sample(index,size=length(index),replace=TRUE)
                 # bootData=bind_rows(lapply(bootIndex,function(zz) data.subset[data.subset[[by]]==zz,]))
                 # faster:
                 bootIndex = data.frame(sample(index,
                                               size = length(index),
                                               replace = TRUE))
                 colnames(bootIndex) = by
                 bootData = merge(bootIndex,
                                  data.subset,
                                  by = by)
                 bootData
               })
               attr(bootDatalist, "inverseOrder") = attr(object$data, "inverseOrder")
               attr(bootDatalist, "algorithm") = attr(object$data, "algorithm")
               attr(bootDatalist, "case") = attr(object$data, "case")
               attr(bootDatalist, "check") = FALSE
               object$FUN(bootDatalist)$mat
             },
             .parallel = parallel,
             .progress = progress)

  rankmatlist = lapply(res[[1]],
                       function(z) z[, "rank", drop = F]
                       )
  for (j in 2:length(res)) {
    rankmatlist = quickmerge.list(rankmatlist,
                                  lapply(res[[j]],
                                         function(z)  z[, "rank", drop = F]))
  }

  aggmatlist = lapply(res[[1]],
                      function(z) z[, -2, drop = F])
  for (j in 2:length(res)) {
    aggmatlist = quickmerge.list(aggmatlist,
                                 lapply(res[[j]],
                                        function(z) z[, -2, drop = F]))
  }

  final=list(bootsrappedRanks=rankmatlist,
             bootsrappedAggregate=aggmatlist,
             data=object$data,
             matlist=tidy.matlist,
             FUN=object$FUN,
             FUN.list=object$FUN.list)
  class(final)=c("bootstrap.list")
  final
}






####################################################################################################
# deprecate following functions?



rankFrequencies <- function(object,...) UseMethod("rankFrequencies")
rankFrequencies.default <- function(object, ...) stop("not implemented for this class")

rankFrequencies.bootstrap=function(object, who,...){
  if (is.data.frame(who)) who=rownames(who)
  if (length(who)==1){
    res=table(t(object$bootsrappedRanks[rownames(object$bootsrappedRanks)==who,]))
    cat("\n",who,"\n")
    print(res)
  } else {
    res=lapply(who, function(w){
      rr=table(t(object$bootsrappedRanks[rownames(object$bootsrappedRanks)==w,]))
    cat(w,"\n")
      print(rr)
      cat("\n")
      rr
    })
  }
  res=c(list(rankFrequencies=res),object)
  invisible(res)
}

rankFrequencies.bootstrap.list=function(object, who,...){
  if (is.data.frame(who)) who=rownames(who)
  res=lapply(object$bootsrappedRanks,function(bootMat){
    if (length(who)==1){
      res=table(t(bootMat[rownames(bootMat)==who,]))
      cat("\n",who,"\n")
      print(res)
    } else {
      res=lapply(who, function(w){
        rr=table(t(bootMat[rownames(bootMat)==w,]))
        cat(w,"\n")
        print(rr)
        cat("\n")
        rr
      })
    }
    res
  })
  res=c(list(rankFrequencies=res),object)
  invisible(res)
}




winnerFrequencies <- function(object,...) UseMethod("winnerFrequencies")
winnerFrequencies.default <- function(object, ...) stop("not implemented for this class")

# Achtung: bester rank muss ==1 sein und nicht z.B. 1.5
winnerFrequencies.bootstrap=function(object,...){
  rankings_dicho=ifelse(object$bootsrappedRanks==1,1,0)
  winnerFrequencies=data.frame(winnerFrequency=rowSums(rankings_dicho),row.names = rownames(object$bootsrappedRanks))
  res=merge(object$mat,winnerFrequencies,by="row.names",...)
  rownames(res)=res[,1]
  res=res[,-1]
  # res=c(res=res,object)
  # class(res)="bootstrapResults"
  res
}

winnerFrequencies.bootstrap.list=function(object,...){
  res=lapply(1:length(object$bootsrappedRanks),function(id){
    rankings_dicho=ifelse(object$bootsrappedRanks[[id]]==1,1,0)
    winnerFrequencies=data.frame(winnerFrequency=rowSums(rankings_dicho),row.names = rownames(object$bootsrappedRanks[[id]]))
    res=merge(object$matlist[[id]],winnerFrequencies,by="row.names",...)
    rownames(res)=res[,1]
    res=res[,-1]
    res
  })
  names(res)=names(object$bootsrappedRanks)
  res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/Rank.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

Rank <- function(object,...) UseMethod("Rank")
Rank.default <- function(object, ...) rank(object,...)  #base::rank

Rank.list <- function(object,
                      x,
                      annotator,
                      ties.method="min",
                      smallBetter=TRUE,
                      ...){

    call=match.call(expand.dots = T)
    annotator.missing=missing(annotator)
    if (any(sapply(object,
                   function(task) {
                     (attr(object,"check") &&
                      smallBetter &&
                      any(is.na(task[[x]])) &&
                      min(task[[x]], na.rm=TRUE)==0)
                  })
            )) {
        message("There are missing metric values and metric values exactly equal to zero.
                 Have some actually missing values been entered as zero in some instances?
                 If yes, specify optional argument na.treat=0 in as.challenge().")
    }

    matlist=lapply(object,
                   function(task){
                     if (annotator.missing){
                       res=bind_rows(
                         lapply(split(task,
                                      task[[attr(object,"case")]]),
                                function(task.case)
                                  cbind(task.case,
                                        rank=rankNA2(task.case[[x]],
                                                     ties.method = ties.method,
                                                     smallBetter = smallBetter)
                                        )
                                )
                         )
                        class(res)[2]="ranked"
                        res
                       } else {
                         byAnnotator=split(task,
                                           as.list(task[,annotator]))
                         temp=bind_rows(
                           lapply(byAnnotator,
                                  function(annotator){
                                    bind_rows(
                                      lapply(split(annotator,
                                                   annotator[[attr(object,"case")]]),
                                             function(annotator.case)
                                               cbind(annotator.case,
                                                     rank=rankNA2(annotator.case[[x]],
                                                                  ties.method = ties.method,
                                                                  smallBetter = smallBetter)
                                                     )
                                             )
                                    )
                                    }
                                  )
                           )
                         class(temp)[2]="ranked"
                         temp
                         }
                     }
                   )
    res=list(FUN = . %>% (call),
             call=list(call),
             data=object,
             matlist=matlist)

    class(res)=c("ranked.list",class(res))
    res
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/subset.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

subset <- function(x,...) UseMethod("subset")
subset.default <- function(x, ...) base::subset(x, ...)


subset.comparedRanks.list=function(x,
                                   tasks,...){
  res=x[tasks]
  class(res)="comparedRanks.list"
  res
}

subset.list=function(x,
                     tasks,...){
  x[tasks]
}

subset.aggregated.list=function(x,
                                tasks,...){
  call=match.call(expand.dots = T)
  if (!is.null(as.list(call$top))) stop("Subset of algorithms only sensible for single task challenges.")
  matlist=x$matlist[tasks]
  res=list(matlist=matlist,
           call=list(x$call,call),
           data=x$data,
           FUN =  . %>% (x$FUN) %>%  (call)
  )

  class(res)=class(x)
  res

}

which.top=function(object,
                   top){
  mat=object$mat[object$mat$rank<=top,]
  rownames(mat)#[order(mat$rank)]
}

#' Extracts a subset of algorithms or tasks
#'
#' Extracts the top performing algorithms or a subset of tasks.
#'
#' @section Reports for subsets (top list) of algorithms:
#' If ties are present in the ranking, the subset will consist of more than \code{top} algorithms.
#' Line plots for ranking robustness can be used to check whether algorithms performing well in other
#' ranking methods are excluded. Bootstrapping still takes entire uncertainty into account.
#' Podium plots and ranking heatmaps neglect excluded algorithms. Only available for single-task challenges
#' (for multi-task challenges not sensible because each task would contain a different set of algorithms).
#'
#' @section Reports for subsets of tasks:
#' You may want to recompute the consensus ranking after creating the subset. An error will be raised
#' if a task identifier is not contained in the assessment data set to avoid subsequent errors.
#'
#'
#' @param x The ranked asssessment data set.
#' @param top A positive integer specifying the amount of top performing algorithms to be retrieved.
#' @param tasks A vector of strings containing the task identifiers that should remain in the subset.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return An S3 object of class "ranked.list" to represent a ranked assessment data set.
#'
#' @examples
#'
#' \dontrun{
#'  # only show the top 3 algorithms according to the chosen ranking method
#'  subset(ranking, top = 3) %>% report(...)
#' }
#'
#' \dontrun{
#'  # restrict report to tasks "task1" and "task2"
#'  subset(ranking, tasks=c("task1", "task2")) %>% report(...)
#' }
#'
#' @export
subset.ranked.list <- function(x,
                               top,
                               tasks,...) {

  if (!missing(top) & length(x$matlist) != 1)  stop("Subset of algorithms only sensible for single-task challenges. Otherwise no consensus ranking is possible.")

  if (!missing(top)){
    taskMat <- x$matlist[[1]]
    taskData <- x$data[[1]]
    objectTop=x
    objectTop$matlist[[1]]=taskMat[taskMat$rank<=top,]

    taskMatRowNames <- rownames(objectTop$matlist[[1]])
    attribute <- attr(objectTop$data,"algorithm")

    selectedRowNames <- taskData[[attribute]] %in% taskMatRowNames
    objectTop$data[[1]] <- taskData[selectedRowNames,]
    if (is.factor(objectTop$data[[1]][[attribute]])) objectTop$data[[1]][[attribute]] <- droplevels(objectTop$data[[1]][[attribute]])

    objectTop$fulldata=x$data
    return(objectTop)
  } else if (!missing(tasks)){

    if (is.character(tasks) && any(!tasks%in%names(x$matlist))) {
      stop("There is/are no task(s) called ",paste(tasks[!tasks%in%names(x$matlist)],collapse = " and "),".")
    }
    res=list(matlist=x$matlist[tasks],
             data=x$data[tasks],
             call=x$call,
             FUN=x$FUN,
             FUN.list=x$FUN.list
    )

    attrib=attributes(x$data)
    attrib$names=attr(res$data,"names")
    attributes(res$data)=attrib
    class(res)=c("ranked.list","list")
    return(res)
  }
}


#' Extracts a subset of algorithms or tasks
#'
#' Extracts the top performing algorithms or a subset of tasks.
#'
#' @section Reports for subsets (top list) of algorithms:
#' If ties are present in the ranking, the subset will consist of more than \code{top} algorithms.
#' Line plots for ranking robustness can be used to check whether algorithms performing well in other
#' ranking methods are excluded. Bootstrapping still takes entire uncertainty into account.
#' Podium plots and ranking heatmaps neglect excluded algorithms. Only available for single-task challenges
#' (for multi-task challenges not sensible because each task would contain a different set of algorithms).
#'
#' @section Reports for subsets of tasks:
#' You may want to recompute the consensus ranking after creating the subset. An error will be raised
#' if a task identifier is not contained in the assessment data set to avoid subsequent errors.
#'
#'
#' @param x The bootstrapped, ranked asssessment data set.
#' @param top A positive integer specifying the amount of top performing algorithms to be retrieved.
#' @param tasks A vector of strings containing the task identifiers that should remain in the subset.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return An S3 object of class "bootstrap.list" to represent a bootstrapped, ranked assessment data set.
#'
#' @examples
#'
#' \dontrun{
#'  # only show the top 3 algorithms according to the chosen ranking method
#'  subset(ranking_bootstrapped, top = 3) %>% report(...)
#' }
#'
#' \dontrun{
#'  # restrict report to tasks "task1" and "task2" and recompute consensus ranking
#'  meanRanks <- subset(ranking, tasks = c("task1", "task2")) %>% consensus(method = "euclidean")
#' }
#'
#' @export
subset.bootstrap.list=function(x,
                               top,
                               tasks, ...) {

  if (!missing(top) & length(x$matlist) != 1)  stop("Subset of algorithms only sensible for single-task challenges. Otherwise no consensus ranking is possible.")

  if (!missing(top)){
    objectTop <- subset.ranked.list(x, top = top)

    objectTop$bootsrappedRanks[[1]] <- objectTop$bootsrappedRanks[[1]][rownames(objectTop$matlist[[1]]),]
    objectTop$bootsrappedAggregate[[1]] <- objectTop$bootsrappedAggregate[[1]][rownames(objectTop$matlist[[1]]),]
    return(objectTop)
  } else if (!missing(tasks)){
    if (is.character(tasks) && any(!tasks%in%names(x$matlist))) {
      stop("There is/are no task(s) called ",paste(tasks[!tasks%in%names(x$matlist)],collapse = " and "),".")
    }

    res=list(bootsrappedRanks=x$bootsrappedRanks[tasks],
             bootsrappedAggregate=x$bootsrappedAggregate[tasks],
             matlist=x$matlist[tasks],
             data=x$data[tasks],
             FUN=x$FUN
    )

    attrib=attributes(x$data)
    attrib$names=attr(res$data,"names")
    attributes(res$data)=attrib
    class(res)="bootstrap.list"
    return(res)
  }
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/rankingMethods.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' Performs ranking via aggregate-then-rank
#'
#' Performs ranking by first aggregating performance values across all cases (e.g., with the mean, median or another quantile) for each algorithm.
#' This aggregate is then used to compute a rank for each algorithm.
#'
#' @param object The challenge object.
#' @param FUN The aggregation function, e.g. mean, median, min, max, function(x), quantile(x, probs=0.05).
#' @param ties.method A string specifying how ties are treated, see [base::rank()].
#' @param ... Further arguments passed to or from other functions.
#'
#' @return An S3 object of class "ranked.list" to represent a ranked assessment data set.
#'
#' @examples
#'
#' \dontrun{
#'  aggregateThenRank(challenge, FUN = mean, ties.method = "average", na.treat = 0)
#' }
#'
#' @family ranking functions
#' @export
aggregateThenRank=function(object,FUN,ties.method = "min",...){
  object %>%
    aggregate(FUN=FUN,...) %>%
    rank(ties.method = ties.method)
}

#' Performs ranking via test-then-rank
#'
#' Computes statistical hypothesis tests based on Wilcoxon signed rank test for each possible
#' pair of algorithms to assess differences in metric values between the algorithms.
#' Then ranking is performed according to the number of significant one-sided test results.
#' If algorithms have the same number of significant test results, then they obtain the same rank.
#'
#' @param object The challenge object.
#' @param ties.method A string specifying how ties are treated, see [base::rank()].
#' @param ... Further arguments passed to or from other functions.
#'
#' @return An S3 object of class "ranked.list" to represent a ranked assessment data set.
#'
#' @examples
#' \dontrun{
#'  testThenRank(challenge,
#'               alpha=0.05, # significance level
#'               p.adjust.method="none", # method for adjustment for multiple testing, see ?p.adjust
#'               na.treat = 0)
#' }
#'
#' @family ranking functions
#' @export
testThenRank=function(object, ties.method = "min",...){
  object %>%
    aggregate(FUN="significance",...) %>%
    rank(ties.method = ties.method)
}

#' Performs ranking via rank-then-aggregate
#'
#' Performs ranking by first computing a rank for each case for each algorithm ("rank first").
#' The final rank is based on the aggregated ranks for the cases. This ranking method handles missing values implicitly
#' by assigning the worst rank to missing algorithm performances.
#'
#'
#' @param object The challenge object.
#' @param FUN The aggregation function, e.g., mean, median, min, max, function(x), quantile(x, probs=0.05).
#' @param ties.method A string specifying how ties are treated, see [base::rank()].
#'
#' @return An S3 object of class "ranked.list" to represent a ranked assessment data set.
#'
#' @examples
#' \dontrun{
#'  rankThenAggregate(challenge, FUN = mean)
#' }
#'
#' @family ranking functions
#' @export
rankThenAggregate=function(object,
                           FUN,
                           ties.method = "min"
                           ){
  object %>%
        rank(ties.method = ties.method)%>%
          aggregate(FUN=FUN) %>%
          rank(ties.method = ties.method) # small rank is always best, i.e. smallBetter always TRUE
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/extract.workflow.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

extract.workflow=function(x) x$FUN


# FILE: /mnt/data/challengeR_extracted/challengeR/R/default_colors.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

default_colors=
  function(n = length(algorithms), algorithms = NULL) {
    # Based on ggplot2:::ScaleHue
    h <- c(0, 360) + 15
    l <- 65
    c <- 100
    
    start <-0# 1
    direction <- 1
    
    rotate <- function(x) (x + start) %% 360 * direction
    
    if ( (diff(h) %% 360) < 1 ) {
      h[2] <- h[2] - 360 / n
    }
    
    structure(grDevices::hcl(h = rotate(seq(h[1], h[2], length = n)),
                             c = c, l = l),
              names = algorithms)
  }


# FILE: /mnt/data/challengeR_extracted/challengeR/R/melt.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

melt.ranked.list=melt.aggregated.list=function(object,...){
  matlist=lapply(object$matlist, function(z){
    z$algorithm=rownames(z)
    z
  })
  melt(matlist,id.vars="algorithm",...)
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/benchmarkUtils.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

# to link with benchmark package (CRAN archived)

as.warehouse.challenge=function(x,...){
  x$.ds="data"
  x$.perf="perf"
  form=as.formula(paste(attr(x,"case"),attr(x,"algorithm"),".perf",".ds",sep="~"))
   ar=acast(x,form,value.var = attr(x,"value"))
   
#   ar=acast(dd,case~alg_name~score~subtask,value.var = attr(object,"value"))
  names(dimnames(ar))  =c("samp", "alg" , "perf", "ds")
  w=benchmark::as.warehouse.array4dim(ar)
  apm <- w$viewAlgorithmPerformance(performances = "perf",datasets="data")
  attr(apm,"challenge")=attributes(x)[-(1:2)]
 apm
}




# FILE: /mnt/data/challengeR_extracted/challengeR/R/dendrogram.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
dendrogram <- function(object,...) UseMethod("dendrogram")

#' @export
dendrogram.default <- function(object, ...) stop("not implemented for this class")

#' Creates a cluster dendrogram
#'
#' Creates a cluster dendrogram from a ranked assessment data set.
#'
#' @param object The ranked assessment data set.
#' @param dist A string specifying the distance measure to be used, see [relations::dissimilarity()].
#' @param method A string specifying agglomeration method to be used, see [stats::hclust()].
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize cross-task insights
#' @export
dendrogram.ranked.list <- function(object,
                                   dist = "symdiff", #the distance measure to be used. see ?relation_dissimilarity
                                   method = "complete", #the agglomeration method to be used. see ?hclust
                                   ... # arguments passed to stats:::plot.hclust
                                   ){
  relensemble=as.relation.ranked.list(object)
  d <- relation_dissimilarity(relensemble,
                              method = dist)
  clust <- hclust(d,
                  method=method)
  dots <- match.call(expand.dots = FALSE)$...
  if (is.null(dots$xlab)) dots$xlab <- ""
  if (is.null(dots$sub)) dots$sub <- ""
  if (is.null(dots$main)) dots$main <- paste0("Cluster Dendrogram (", method, " agglomeration)")

  do.call(plot,
          c(list(x = clust), dots) )
    invisible(list(dist = d,
                   hclust = clust
                   ))

}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/report.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
report <- function(object,...) UseMethod("report")

#' @export
report.default <- function(object, ...) stop("not implemented for this class")

#' Generates a benchmarking report with bootstrapping results
#'
#' Generates a benchmarking report in PDF, HTML or Word format with bootstrapping results.
#' It contains the rankings, plots of the raw assessment data and plots of the ranking stability.
#' For multi-task challenges, it also contains plots of cross-task insights. If you are interested in
#' the individual plots as separate files, set argument \code{clean} to \code{FALSE} and specify \code{fig.format}.
#'
#' @param object The ranked (bootstrapped) assessment data set.
#' @param consensus The rank aggregation across tasks (consensus ranking). Only needed for a multi-task data set.
#' @param file A string specifying the file name of the report. It allows for specifying the output file path as well,
#'   otherwise the working directory is used. If \code{file} does not have a file extension, an extension will be automatically
#'   added according to the output format given in \code{format}. If the argument is omitted, the report is created in a
#'   temporary folder with file name "report".
#' @param title A string specifying the title of the report.
#' @param colors The color scheme that is applied to the plots.
#' @param format A string specifying the format of the report. The options are "PDF", "HTML" or "Word".
#' @param latex_engine A string specifying the LaTeX engine for producing PDF output. The Options are "pdflatex", "lualatex", and "xelatex".
#' @param clean A boolean indicating whether intermediate files (e.g. individual plots) should be kept. Using \code{TRUE} will clean
#'   intermediate files that are created during rendering.
#' @param fig.format A vector of strings containing the file format of the figures that are not removed if \code{clean} is set to \code{FALSE}.
#'   The options are "jpeg", "png" and "pdf", e.g. \code{fig.format = c("jpeg", "png", "pdf")}.
#' @param dpi A positive integer specifying the resolution of the generated plot (\code{fig.format} "jpeg" or "png") in dots per inch (DPI).
#' @param open A boolean specifying whether the report should be opened with the default system viewer after generation.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#' @export
report.bootstrap.list=function(object,
                               consensus,
                               file,
                               title="<Challenge name>",
                               colors=default_colors,
                               format="PDF",
                               latex_engine="pdflatex",
                               clean=TRUE,
                               fig.format = NULL, # file format of figures if clean==FALSE, can be vector, e.g. fig.format=c('jpeg','png', 'pdf')
                               dpi = 150, # DPI, relevant for bitmaps if clean==FALSE and fig.format specified
                               open=TRUE,...){

  # if any missing performance value and na.treat not given in as.challenge stop
  if (is.null(attr(object$data,"na.treat")) && 
      any(sapply(object$data, 
                 function(task) any(is.na(task[[attr(object$data,"value")]]))))) {
    stop("Please specify na.treat in as.challenge().")
  }
  
  # Copy the report file to a temporary directory before processing it, in
  # case we don't have write permissions to the current working dir (which
  # can happen when deployed).
  if (missing(file)) tempReport <- file.path(tempdir(), "report.Rmd")
  else {
    a=strsplit(file,"/")[[1]]
    path=paste0(a[-length(a)],collapse="/")
    if (path=="") tempReport=file.path(paste0(strsplit(a[length(a)],
                                                       ".",
                                                       fixed=T)[[1]][1],".Rmd"))
    else tempReport=file.path(path,paste0(strsplit(a[length(a)],
                                                   ".",
                                                   fixed=T)[[1]][1],".Rmd"))
  }
  file.copy(file.path(system.file("appdir", package = "challengeR"),
                      "report.Rmd"),
            tempReport,
            overwrite = TRUE)

  if (length(object$matlist) > 1) {
    consensus = consensus
    isMultiTask = TRUE
  }
  else {
    consensus = NULL
    isMultiTask = FALSE
  }

  bootstrappingEnabled = TRUE

  if (is(object, "ranked.list")) {
    bootstrappingEnabled = FALSE
  }

  # Set up parameters to pass to Rmd document
  if (!is.null(fig.format) & format=="PDF") fig.format=c("pdf",fig.format)
  if (!is.null(fig.format) && fig.format[1]=="pdf" && format=="Word") fig.format <- c(fig.format[-1], fig.format[1]) # in word avoid use of pdf to be embedded in document
  params <- list(
    object=object,
    consensus=consensus,
    name=title,
    colors=colors,
    isMultiTask=isMultiTask,
    bootstrappingEnabled=bootstrappingEnabled,
    fig.format = fig.format,
    dpi = dpi
  )

  # Knit the document, passing in the `params` list, and eval it in a
  # child of the global environment (this isolates the code in the document
  # from the code in this app).
  out <- render(tempReport,
                switch(
                  format,
                  PDF = pdf_document(number_sections=T,
                                     latex_engine=latex_engine),
                  HTML = html_document(number_sections=T),
                  Word = word_document(df_print="kable")
                  ),
                params = params,
                envir = new.env(parent = globalenv()),
                clean = clean,
                ...
  )

  if (!missing(file)){
    if (is.na(strsplit(file,".",fixed=T)[[1]][2])) file=paste0(file,
                                                               ".",
                                                               strsplit(out,".",fixed=T)[[1]][2])
    file.rename(out, file)
  } else file=out

  file.remove(tempReport)

  if (open) system(paste0('open "', file, '"'))
}

#' Generates a benchmarking report without bootstrapping results
#'
#' Generates a benchmarking report in PDF, HTML or Word format without bootstrapping results.
#' It contains the rankings, plots of the raw assessment data and plots of the ranking stability.
#' For multi-task challenges, it also contains plots of cross-task insights. If you are interested in
#' the individual plots as separate files, set argument \code{clean} to \code{FALSE} and specify \code{fig.format}.
#'
#' @param object The ranked assessment data set.
#' @param consensus The rank aggregation across tasks (consensus ranking). Only needed for a multi-task data set.
#' @param file A string specifying the file name of the report. It allows for specifying the output file path as well,
#'   otherwise the working directory is used. If \code{file} does not have a file extension, an extension will be automatically
#'   added according to the output format given in \code{format}. If the argument is omitted, the report is created in a
#'   temporary folder with file name "report".
#' @param title A string specifying the title of the report.
#' @param colors The color scheme that is applied to the plots.
#' @param format A string specifying the format of the report. The options are "PDF", "HTML" or "Word".
#' @param latex_engine A string specifying the LaTeX engine for producing PDF output. The Options are "pdflatex", "lualatex", and "xelatex".
#' @param clean A boolean indicating whether intermediate files (e.g. individual plots) should be kept. Using \code{TRUE} will clean
#'   intermediate files that are created during rendering.
#' @param fig.format A vector of strings containing the file format of the figures that are not removed if \code{clean} is set to \code{FALSE}.
#'   The options are "jpeg", "png" and "pdf",  e.g. \code{fig.format = c("jpeg", "png", "pdf")}.
#' @param dpi A positive integer specifying the resolution of the generated plot (\code{fig.format} "jpeg" or "png") in dots per inch (DPI).
#' @param open A boolean specifying whether the report should be opened with the default system viewer after generation.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#' @export
report.ranked.list=function(object,
                            consensus,
                            file,
                            title="<Challenge name>",
                            colors=default_colors,
                            format="PDF",
                            latex_engine="pdflatex",
                            clean=TRUE,
                            fig.format = NULL, # file format of figures if clean=FALSE, can be vector, e.g. fig.format=c('jpeg','png', 'pdf')
                            dpi = 150, # DPI, relevant for bitmaps if clean==FALSE and fig.format specified
                            open=TRUE,
                            ...){
  report.bootstrap.list(object, consensus, file, title, colors, format, latex_engine, clean, fig.format, dpi, open, ...)
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/testBased.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

decision <- function(x,...) UseMethod("decision")
decision.default <- function(x, ...) stop("not implemented for this class")

decision.challenge=function(x,
                            na.treat=NULL, #  it can be 'na.rm', numeric value or function
                            alpha=0.05,
                            p.adjust.method="none",
                            alternative="one.sided",
                            test.fun=function(x,y) wilcox.test(x,y,
                                                               alternative = alternative,exact=FALSE,
                                                               paired = TRUE)$p.value,
                            parallel=FALSE,
                            progress="none",...){

  if (is.null(na.treat)){ #na.treat only optional if no missing values in data set
    if (!inherits(x,"list")){
      if (!any(is.na(x[,attr(x, "value")]))) na.treat="na.rm" # there are no missings so set na.treat by dummy "na.rm" has no effect
      else stop("Please specify na.treat in as.challenge()")
    } else {
      if (!any(sapply(x,
                      function(task) any(is.na(task[,attr(x, "value")]))))) na.treat="na.rm" # there are no missings so set na.treat by dummy "na.rm" has no effect
      else stop("Please specify na.treat in as.challenge()")
    }
  }


  if (alternative!="two.sided") alternative=ifelse(!attr(x,"smallBetter"),
                                                   yes="greater",
                                                   no="less")
  call=match.call(expand.dots = T)

  object=x
  algorithm=attr(object,"algorithm")
  case=attr(object,"case")
  value=attr(object,"value")
  smallBetter=attr(object,"smallBetter")
  if(missing(case)| missing(smallBetter)) stop("arguments case and alpha need to be given in as.challenge()")


  if (inherits(object,"list")){
    matlist=llply(1:length(object),
                  function(id){
                    piece=object[[id]]
                    if (length(unique(piece[[algorithm]]))<=1){
                      warning("only one ", algorithm, " available in element ", names(object)[id])
                    }
                    if (is.numeric(na.treat)) piece[,value][is.na(piece[,value])]=na.treat
                    else if (is.function(na.treat)) piece[,value][is.na(piece[,value])]=na.treat(piece[,value][is.na(piece[,value])])
                    else if (na.treat=="na.rm") piece=piece[!is.na(piece[,value]),]
                    mat=Decision(piece, value, algorithm, case, alpha, smallBetter,
                                 p.adjust.method=p.adjust.method,
                                 alternative=alternative,
                                 test.fun=test.fun)
                    mat=as.data.frame(mat)
                    mat[is.na(mat)]=0
                    mat=as.matrix(mat)
                    class(mat)=c(class(mat),"challenge.incidence")
                    mat

                  },
                  .parallel=parallel,
                  .progress=progress )
    names(matlist)=names(object)
    return(matlist)
  } else {
    if (length(unique(object[[algorithm]]))<=1){
      warning("only one ", algorithm, " available")
      matlist=(matrix(NA,1,1))
    } else {
      mat=Decision(object,
                   value,
                   algorithm,
                   case,
                   alpha,
                   smallBetter,
                   p.adjust.method=p.adjust.method,
                   alternative=alternative,
                   test.fun=test.fun)
    }
    mat=as.data.frame(mat)
    mat[is.na(mat)]=0
    mat=as.matrix(mat)
    class(mat)=c(class(mat),"challenge.incidence")
    return(mat)

  }
}


Decision=function(object,
                  value,
                  by,
                  case,
                  alpha,
                  smallBetter=TRUE,
                  p.adjust.method="none",
                  alternative="one.sided",
                  test.fun=function(x,y) wilcox.test(x,y,
                                                     alternative = alternative,exact=FALSE,
                                                     paired = TRUE)$p.value){
  algorithms=unique(object[[by]])
  if (length(unique(object[[case]]))==1){
    warning("Only one case in task.")
  }

  combinations=expand.grid(algorithms,algorithms)[,2:1]
  combinations=combinations[apply(combinations,1,function(z) anyDuplicated(z)==0),] # remove i==j

  pvalues=sapply(1:nrow(combinations), function(it){
    dat1=object[object[[by]]==combinations[it,1],]
    dat2=object[object[[by]]==combinations[it,2],]
    id=intersect(dat2[,case],dat1[,case])
    dat1=dat1[match(id,dat1[,case]),value]
    dat2=dat2[match(id,dat2[,case]),value]
    test.fun(dat1,dat2)

  })
  decisions=as.numeric(p.adjust(pvalues,
                                method=p.adjust.method)<= alpha)
  res=cbind(combinations,decisions)
  reshape2::acast(res,
                  Var2~Var1,
                  value.var="decisions")
}


as.relation.challenge.incidence=function(x,
                                         verbose = FALSE, ...) {
  r <- relation(incidence = x, ...)

  props <- check_strict_preference(r)
  class <- "strictpref"
  r$.Meta$is_decreasing <- FALSE

  r$.Meta <- c(r$.Meta,
               structure(props, names = sprintf("is_%s", names(props))))

  if ( verbose ) {
    for ( p in names(props) ) {
      cat(sprintf("%s = %s:\n", p, props[[p]]))
      print(relation_violations(r, p, TRUE))
    }
  }

  structure(r, class = c(class, class(r)))
}

check_strict_preference=
function(x) {
  list(irreflexive = relation_is_irreflexive(x),
       asymmetric = relation_is_asymmetric(x),
       transitive = relation_is_transitive(x),
       negatively_transitive = relation_is_negatively_transitive(x),
       trichotomous = relation_is_trichotomous(x))
}


significance=function(object,
                      value,
                      algorithm,
                      case,
                      alpha,
                      smallBetter=TRUE,...) {

  xx=as.challenge(object,
                  value=value,
                  algorithm=algorithm,
                  case=case,
                  smallBetter = smallBetter,
                  check=FALSE)
  a=decision.challenge(xx, alpha=alpha, ...)
  prop_significance=rowSums(a)/(ncol(a)-1)
  return(data.frame("prop_significance"=prop_significance,
                    row.names = names(prop_significance)))
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/S3.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

utils::globalVariables(c("."))

"+.ggList" <- function (e1, e2){
  pp <- e1
  if(is.ggplot(pp)) plotList <- list(pp)
  else if(is.list(pp)) plotList <- pp
  else stop("Can't handle an object of class ", class(pp))

  for(i in 1:length(plotList)){
    p <- plotList[[i]]
    if(is.ggplot(p)) plotList[[i]] <- p + e2
  }

  if(is.ggplot(pp)) plotList[[1]]
  else plotList
}

"%++%" <- `+.ggList`

print.ranked.list <-function(x,...)  print(x$matlist, ...)
print.aggregated.list <-function(x,...)  print(x$matlist, ...)
print.aggregated <-function(x,...)  print(x$mat,...)
print.ranked <-function(x,...)  print(x$mat[order(x$mat$rank),],...)
print.ggList <- function(x, ...) {
  for(i in 1:length(x)) print(x[[i]])
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/select.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

select.if <- function(object,...) UseMethod("select.if")
select.if.default <- function(object, ...) stop("not implemented for this class")

select.if.comparedRanks.list=function(object,FUN,...){
  #if (!missing(FUN)) 
    res=object[sapply(object, function(x) do.call(FUN,args=list(x=x$mat)))]
  #if (!missing(which)) res=object[which]
   class(res)="comparedRanks.list"
  res
}

select.if.list=function(object,FUN,...){
  res=object[sapply(object, function(x) do.call(FUN,args=list(x=x)))]
  res
}



select.if.aggregated.list=select.if.ranked.list=function(object,FUN,...){
  call=match.call(expand.dots = T)  
  matlist=object$matlist
  #if (!missing(FUN)) 
    matlist=matlist[sapply(matlist, function(x) do.call(FUN,args=list(x=x)))]
  #if (!missing(which)) matlist=matlist[which]
  
  res=list(matlist=matlist,
           call=list(object$call,call),
           data=object$data,
       FUN =  . %>% (object$FUN) %>%  (call)
      )

  class(res)=class(object)
  res
    
}




# FILE: /mnt/data/challengeR_extracted/challengeR/R/compareRanks.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

kendall=function(a,b) cor(a,b,method="kendall")
spearmansWeightedFootrule=function(a,b)  sum(abs(a-b)/pmin(a,b))
spearmansFootrule=function(a,b)  sum(abs(a-b))
# SpearmansFootrule=function(a,b)  sum(abs(match(a, b) - a))
# SpearmansWeightedFootrule=function(a,b)  sum(abs(match(a, b) - a)/pmin(a,b))


compareRanks <- function(x,...) UseMethod("compareRanks")
compareRanks.default <- function(x, ...) stop("not implemented for this class")


 compareRanks.ranked.list <-function(x,
                                     y,
                                     FUN=kendall,...){
    matlist=merge.list(x$matlist,
                       y$matlist
                       ,...)
    res=lapply(1:length(matlist), 
               function(z){
                 tau=FUN(matlist[[z]][,"rank.1"],
                         matlist[[z]][,"rank.2"])
                 res=list(tau=tau,
                          mat=matlist[[z]])
                 class(res)="comparedRanks"
                 res
                 })
    names(res)=names(matlist)
    class(res)="comparedRanks.list"
   res
  }




print.comparedRanks <-
function(x,...)  {
  cat("\n")
  print(x$mat)
  cat("\nKendall's tau =",x$tau,"\n-------------------------------------------------------\n")
 }




# FILE: /mnt/data/challengeR_extracted/challengeR/R/boxplot.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' Creates dot- and boxplots
#'
#' Creates dot- and boxplots visualizing the assessment data separately for each algorithm.
#' Boxplots representing descriptive statistics for all test cases (median, quartiles and outliers)
#' are combined with horizontally jittered dots representing individual test cases.
#'
#' @param x The ranked assessment data set.
#' @param color A string specifying the color of the dots.
#' @param jitter.width A numeric value specifying the jitter width of the dots.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize assessment data
#' @export
boxplot.ranked.list=function(x,
                             jitter.width=0.25,...){
  algo=attr(x$data,"algorithm")
  value=attr(x$data,"value")
  ranking=x
  x=x$data

  for (i in names(x)) {
    x[[i]][[algo]]=factor(x[[i]][[algo]],
                          levels=rownames(ranking$matlist[[i]][order(ranking$matlist[[i]]$rank),]))
  }

  a=lapply(1:length(x),function(id){
    ggplot(data=x[[id]])+
      geom_jitter(aes_string(algo,value,color=algo),
                  position=position_jitter(width=jitter.width, height=0),
                  ...)+
      geom_boxplot(aes_string(algo,value),
                   outlier.shape = NA,fill=NA)+
      ggtitle(names(x)[id]) +
      theme(axis.text.x=element_text(angle = -90, hjust = 0),
            legend.position="none") +
      xlab("Algorithm") +
      ylab("Metric value") 
  })

  # Remove title for single-task data set
  if (length(a) == 1) {
    a[[1]]$labels$title <- NULL
    return(a[[1]])
  } else {
    names(a) = names(x$matlist)
    class(a) <- "ggList"
    return(a)
 }
}

boxplot.comparedRanks.list=function(x,...){
  tau=sapply(x,function(z) z$tau)
  boxplot(tau,ylim=c(0,1.0),las=2, outline=FALSE,
          ylab="Kendall's tau",...)
  stripchart(tau,
             vertical = TRUE, method = "jitter",
             pch = 21, col = "blue", add=TRUE,...)

}

boxplot.bootstrap.list=function(x,...){
  winner.noboot=winner.ranked.list(x)
  x2=winnerFrequencies(x)
  n.bootstraps= ncol(x$bootsrappedRanks[[1]])
  perc_boot_Winner=lapply(1:length(x2),function(i){
    x2.i=x2[[i]]
    winner.id=which(rownames(x2.i)%in%rownames(winner.noboot[[i]])) #could be multiple winners!!!!
    100*x2.i[winner.id,3,drop=F]/n.bootstraps
  })

  boxplot(unlist(perc_boot_Winner),ylim=c(0,100),las=2, outline=FALSE,
          ylab="% Bootstraps",xlab="Winner ranks 1",
          sub=paste(n.bootstraps,"Bootstraps"),...)
  stripchart(unlist(perc_boot_Winner),
             vertical = TRUE, method = "jitter",
             pch = 21, col = "blue", add=TRUE,...)
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/stability.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

#' @export
stability <- function(x,...) UseMethod("stability")

#' @export
stability.default <- function(x, ...) stop("not implemented for this class")

#' @export
stabilityByAlgorithm <- function(x,...) UseMethod("stabilityByAlgorithm")

#' @export
stabilityByAlgorithm.default <- function(x, ...) stop("not implemented for this class")

#' @export
stabilityByTask <- function(x,...) UseMethod("stabilityByTask")

#' @export
stabilityByTask.default <- function(x, ...) stop("not implemented for this class")

#' Creates a blob plot across tasks
#'
#' Creates a blob plots visualizing the ranking variability across tasks.
#'
#' @param x The ranked asssessment data set.
#' @param ordering
#' @param probs
#' @param max_size
#' @param freq
#' @param shape
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize cross-task insights
#' @export
stability.ranked.list=function(x,
                               ordering,
                               probs=c(.025,.975),
                               max_size=6,
                               freq=FALSE,
                               shape=4,...) {
  if (length(x$data) < 2) {
    stop("The stability of rankings across tasks cannot be computed for less than two tasks.")
  }
  
  dd=melt(x,
          measure.vars="rank",
          value.name="rank") %>% dplyr::rename(task="L1")
  
  if (!missing(ordering)) {
    if (is.numeric(ordering) & !is.null(names(ordering)) ){
      ordering <- names(ordering)[order(ordering)]
    } else if (!is.character(ordering)){
      stop("Argument ordering has to be a named vector of ranks or a vector of algorithm names in the ranking order.")
    }
    dd=dd%>%mutate(algorithm=factor(.data$algorithm,
                                    levels=ordering))
  } else dd=dd%>%mutate(algorithm=factor(.data$algorithm))
  
  if (!freq) {
    p = ggplot(dd)+
      geom_count(aes(algorithm,
                     rank,
                     color=algorithm,
                     size = stat(prop*100)))
  } else {
    p=ggplot(dd)+
      geom_count(aes(algorithm,
                     rank,
                     color=algorithm ))
  }
  
  # Define breaks before creating Blob plot
  if (max(dd$rank)>5) {
    breaks = c(1, seq(5, max(dd$rank), by=5))
  } else {
    breaks = seq(1, max(dd$rank))
  }
  
  p+scale_size_area(max_size = max_size)+
    stat_summary(aes(algorithm, rank),
                 geom="point",
                 shape=shape,
                 fun.data=function(x) data.frame(y=median(x)),...)+
    stat_summary(aes(algorithm, rank),
                 geom="linerange",
                 fun.data=function(x) data.frame(ymin=quantile(x,probs[1]),
                                                 ymax=quantile(x,probs[2])))+
    geom_abline(slope=1,
                color="gray",
                linetype="dotted")+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
    guides(size = guide_legend(title="%"))+
    scale_y_continuous(minor_breaks=NULL,
                       limits=c(.4, max(dd$rank)),
                       breaks=breaks)+
    xlab("Algorithm")+
    ylab("Rank")
  
}


rankdist.bootstrap.list=function(x,...){
  rankDist=melt(lapply(x$bootsrappedRanks,t),
                value.name="rank") %>% dplyr::rename(algorithm="Var2",task="L1")
  rankDist
}

#' Creates blob plots or stacked frequency plots stratified by algorithm
#'
#' Creates blob plots (\code{stacked = FALSE}) or stacked frequency plots (\code{stacked = TRUE}) for each algorithm
#' from a bootstrapped, ranked assessment data set.
#'
#' @param x The bootstrapped, ranked assessment data set.
#' @param ordering
#' @param stacked A boolean specifying whether a stacked frequency plot (\code{stacked = TRUE}) or blob plot (\code{stacked = FALSE}) should be created.
#' @param probs
#' @param max_size
#' @param shape
#' @param freq
#' @param single
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize cross-task insights
#' @export
stabilityByAlgorithm.bootstrap.list=function(x,
                                             ordering,
                                             stacked = FALSE,
                                             probs=c(.025,.975),#only for !stacked
                                             max_size=3,#only for !stacked
                                             shape=4,#only for !stacked
                                             freq=FALSE, #only for stacked
                                             single=FALSE,...) {
  
  if (length(x$data) < 2) {
    stop("The stability of rankings by algorithm cannot be computed for less than two tasks.")
  }
  
  rankDist=rankdist.bootstrap.list(x)
  
  if (!missing(ordering)) {
    if (is.numeric(ordering) & !is.null(names(ordering)) ){
      ordering <- names(ordering)[order(ordering)]
    } else if (!is.character(ordering)){
      stop("Argument ordering has to be a named vector of ranks or a vector of algorithm names in the ranking order.")
    }
    
    rankDist=rankDist%>%mutate(algorithm=factor(.data$algorithm,
                                                levels=ordering))
  }
  
  if (!stacked){
    if (single==FALSE){
      
      # Define breaks before creating Blob plot
      if (max(rankDist$rank)>5) {
        breaks = c(1, seq(5, max(rankDist$rank), by=5))
      } else {
        breaks = seq(1, max(rankDist$rank))
      }
      
      pl <- ggplot(rankDist)+
        geom_count(aes(task ,
                       rank,
                       color=algorithm,
                       size = stat(prop*100),
                       group = task ))+
        scale_size_area(max_size = max_size)+
        stat_summary(aes(task ,rank ),
                     geom="point",
                     shape=shape,
                     fun.data=function(x) data.frame(y=median(x)),...)+
        stat_summary(aes(task ,rank ),
                     geom="linerange",
                     fun.data=function(x) data.frame(ymin=quantile(x,probs[1]),
                                                     ymax=quantile(x,probs[2])))+
        facet_wrap(vars(algorithm))+
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
        guides(size = guide_legend(title="%"))+
        scale_y_continuous(minor_breaks=NULL,
                           limits=c(.4, max(rankDist$rank)),
                           breaks=breaks)+
        xlab("Task")+
        ylab("Rank")
      
    } else {
      pl=list()
      for (alg in ordering){
        rankDist.alg=subset(rankDist,
                            rankDist$algorithm==alg)
        
        # Define breaks before creating Blob plot
        if (max(rankDist$rank)>5) {
          breaks = c(1, seq(5, max(rankDist$rank), by=5))
        } else {
          breaks = seq(1, max(rankDist$rank))
        }
        
        pl[[alg]]=ggplot(rankDist.alg)+
          geom_count(aes(task ,
                         rank,
                         color=algorithm,
                         size = stat(prop*100),
                         group = task ))+
          scale_size_area(max_size = max_size)+
          stat_summary(aes(task ,
                           rank ),
                       geom="point",
                       shape=shape,
                       fun.data=function(x) data.frame(y=median(x)),...)+
          stat_summary(aes(task ,rank ),
                       geom="linerange",
                       fun.data=function(x) data.frame(ymin=quantile(x,probs[1]),
                                                       ymax=quantile(x,probs[2])))+
          facet_wrap(vars(algorithm))+
          theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
          guides(size = guide_legend(title="%"))+
          scale_y_continuous(minor_breaks=NULL,
                             limits=c(.4, max(rankDist$rank)),
                             breaks=breaks)+
          xlab("Task")+
          ylab("Rank")
      }
      names(pl) = ordering
      class(pl) <- "ggList"
    }
    
  } else { #stacked
    rankDist=rankDist%>%
      group_by(task)%>%
      dplyr::count(.data$algorithm,
                   .data$rank)%>%
      group_by(.data$algorithm)%>%
      mutate(prop=.data$n/sum(.data$n)*100)%>%
      ungroup%>%
      data.frame%>%
      mutate(rank=as.factor(.data$rank))
    
    results= melt.ranked.list(x,
                              measure.vars="rank",
                              value.name="rank") %>%
      dplyr::select(-.data$variable)
    colnames(results)[3]="task"
    if (!missing(ordering)) {
      if (is.numeric(ordering) & !is.null(names(ordering)) ){
        ordering <- names(ordering)[order(ordering)]
      } else if (!is.character(ordering)){
        stop("Argument ordering has to be a named vector of ranks or a vector of algorithm names in the ranking order.")
      }
      
      results=results%>%mutate(algorithm=factor(.data$algorithm,
                                                levels=ordering))
    }
    
    if (single==FALSE){
      pl<- ggplot(rankDist) +
        facet_wrap(vars(algorithm))+
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
      
      if (freq){
        pl <- pl +   geom_bar(aes(rank,
                                  n,
                                  fill=task ),
                              position = "stack",
                              stat = "identity") +
          ylab("Frequency")
      } else {
        pl <- pl +   geom_bar(aes(rank,
                                  prop,
                                  fill=task ),
                              position = "stack",
                              stat = "identity")+
          ylab("Proportion (%)")
      }
      
      pl <-  pl +
        geom_vline(aes(xintercept=rank,
                       color=task),
                   size=.4,
                   linetype="dotted",
                   data=results) +
        xlab("Rank")
    } else {
      pl=list()
      for (alg in ordering){
        rankDist.alg=subset(rankDist,
                            rankDist$algorithm==alg)
        results.alg=subset(results,
                           results$algorithm==alg)
        pl[[alg]]=ggplot(rankDist.alg)+
          facet_wrap(vars(algorithm))+
          theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
        
        if (freq){
          pl[[alg]] <- pl[[alg]] +   geom_bar(aes(rank,
                                                  n,
                                                  fill=task ),
                                              position = "stack",
                                              stat = "identity") +
            ylab("Frequency")
        } else {
          pl[[alg]] <- pl[[alg]] +   geom_bar(aes(rank,
                                                  prop,
                                                  fill=task ),
                                              position = "stack",
                                              stat = "identity")+
            ylab("Proportion (%)")
        }
        
        pl[[alg]] <- pl[[alg]] +
          geom_vline(aes(xintercept=rank,
                         color=task),
                     size=.4,
                     linetype="dotted",
                     data=results.alg) +
          xlab("Rank")
      }
      names(pl) = ordering
      class(pl) <- "ggList"
    }
  }
  pl
}

#' Creates blob plots stratified by task
#'
#' Creates blob plots for each task from a bootstrapped, ranked assessment data set.
#'
#' @param x The bootstrapped, ranked assessment data set.
#' @param ordering
#' @param probs
#' @param max_size
#' @param size.ranks
#' @param shape
#' @param showLabelForSingleTask A boolean specifying whether the task name should be used as title for a single-task data set.
#' @param ... Further arguments passed to or from other functions.
#'
#' @return
#'
#' @examples
#'
#' @seealso `browseVignettes("challengeR")`
#'
#' @family functions to visualize ranking stability
#' @family functions to visualize cross-task insights
#' @export
stabilityByTask.bootstrap.list=function(x,
                                        ordering,
                                        probs=c(.025,.975),
                                        max_size=3,
                                        size.ranks=.3*theme_get()$text$size,
                                        shape=4,
                                        showLabelForSingleTask=FALSE,...){
  rankDist=rankdist.bootstrap.list(x)
  ranks=melt.ranked.list(x,
                         measure.vars="rank",
                         value.name = "full.rank")
  colnames(ranks)[4]="task"
  if (!missing(ordering)) {
    if (is.numeric(ordering) & !is.null(names(ordering)) ){
      ordering <- names(ordering)[order(ordering)]
    } else if (!is.character(ordering)){
      stop("Argument ordering has to be a named vector of ranks or a vector of algorithm names in the ranking order.")
    }
    
    ranks$algorithm=factor(ranks$algorithm,
                           levels=ordering)
    rankDist=rankDist%>%mutate(algorithm=factor(.data$algorithm,
                                                levels=ordering))
  }
  
  # Define breaks before creating Blob plot
  if (max(rankDist$rank)>5) {
    breaks = c(1, seq(5, max(rankDist$rank), by=5))
  } else {
    breaks = seq(1, max(rankDist$rank))
  }
  
  blobPlot <- ggplot(rankDist)+
    geom_count(aes(algorithm ,
                   rank,
                   color=algorithm,
                   size = stat(prop*100),
                   group = algorithm ))+
    scale_size_area(max_size = max_size)+
    geom_abline(slope=1,
                color="gray",
                linetype="dotted")+
    stat_summary(aes(algorithm ,rank ),
                 geom="point",
                 shape=shape,
                 fun.data=function(x) data.frame(y=median(x)),...)+
    stat_summary(aes(algorithm ,rank ),
                 geom="linerange",
                 fun.data=function(x) data.frame(ymin=quantile(x,probs[1]),
                                                 ymax=quantile(x,probs[2])))+
    geom_text(aes(x=algorithm,y=1,label=full.rank),
              nudge_y=-.6,
              vjust = 0,
              size=size.ranks,
              fontface="plain",
              family="sans",
              data=ranks) +
    coord_cartesian(clip = 'off')+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+
    guides(size = guide_legend(title="%"))+
    scale_y_continuous(minor_breaks=NULL,
                       limits=c(.4, max(rankDist$rank)),
                       breaks=breaks)+
    xlab("Algorithm")+
    ylab("Rank")
  
    # Create multi-panel plot with task names as labels for multi-task data set or single-task data set when explicitly specified
    if (length(x$data) > 1 || showLabelForSingleTask == TRUE) {
      blobPlot <- blobPlot + facet_wrap(vars(task))
    }
  
  return(blobPlot)
}


# FILE: /mnt/data/challengeR_extracted/challengeR/R/by.R
# Copyright (c) German Cancer Research Center (DKFZ)
# All rights reserved.
#
# This file is part of challengeR.
#
# challengeR is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.
#
# challengeR is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with challengeR. If not, see <https://www.gnu.org/licenses/>.

splitby <-
function(x,by){
    if (length(by)==1) split(x,x[,by])
    else split(x,as.list(x[,by]))
  }
