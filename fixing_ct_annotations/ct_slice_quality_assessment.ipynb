{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902b9193",
   "metadata": {},
   "source": [
    "# CT Slice Quality Assessment with VLLM\n",
    "Adapted from the LabelCritic repo. This notebook:\n",
    "1. Loads 5 random CT slices from a specified folder.\n",
    "2. Prepares a prompt asking the VLLM to rate image quality (1–5).\n",
    "3. Sends the prompt and images to the VLLM server.\n",
    "4. Prints out the model's response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7cd1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "from ErrorDetector import CreateConversation  # assumes LabelCritic repo is in your PYTHONPATH\n",
    "\n",
    "def encode_image(img_path, solid_overlay=False):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "ct_slice_dir = \"path/to/your/ct_slices\"  # <-- CHANGE THIS\n",
    "vllm_url = \"http://localhost:8000/v1/chat/completions\"  # Update if your VLLM uses a different port\n",
    "\n",
    "prompt_text = \"Give score 1–5, how good is the image quality?\"\n",
    "num_slices = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3330557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sample 5 random CT slices ===\n",
    "all_slices = [os.path.join(ct_slice_dir, f) for f in os.listdir(ct_slice_dir) if f.lower().endswith(('.png', '.jpg'))]\n",
    "sampled_slices = random.sample(all_slices, num_slices)\n",
    "\n",
    "for s in sampled_slices:\n",
    "    print(f\"Selected: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create VLLM conversation ===\n",
    "conversation = CreateConversation(\n",
    "    img_file_list=sampled_slices,\n",
    "    text=prompt_text,\n",
    "    conver=[],\n",
    "    prt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6eec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Send prompt to VLLM ===\n",
    "payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",  # or whatever your model is called\n",
    "    \"messages\": conversation,\n",
    "    \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "response = requests.post(vllm_url, json=payload)\n",
    "response.raise_for_status()\n",
    "print(\"Model response:\")\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}